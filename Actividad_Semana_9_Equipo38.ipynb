{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMvm9lYrQlvJxZAhYcSKXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A01793509/Equipo38/blob/main/Actividad_Semana_9_Equipo38.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "###Tecnológico de Monterrey\n",
        "###Profr: Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Adtividad de la Semana 9**\n",
        "###**Taxonomía de Métricas de Clasificación**"
      ],
      "metadata": {
        "id": "LokPbfyA_jmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nombres y matrículas de los integrantes del equipo:**\n",
        "\n",
        "*   Alberto Jose Garcia Porras (A01793509)\n",
        "*   Carlos Julio León Caicedo (A01793947)\n",
        "*   Luis Fernando Ríos Piedra (A00453954)\n",
        "*   Marco Antonio Vázquez Morales (A01793704)"
      ],
      "metadata": {
        "id": "2JVg-Ha7_2UV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumen"
      ],
      "metadata": {
        "id": "JF5glsakAjtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La evaluación de modelos es uno de los aspectos más importantes para en el reconocimiento de patrones, por un lado tenemos la evaluación que esta basada en el valor de la métrica y por otro en la elección de la misma métrica. \n",
        "\n",
        "Existe una variedad de métricas, en especial las relacionadas a clasificación que mostramos a continución:\n",
        "\n",
        "\n",
        "\n",
        "*   Métricas basadas en un unbral y una comprensión cualitativa del error\n",
        "*   Métricas basadas en una compresión probabilistica del error\n",
        "*   Métricas basadas en que también se clasifica un modelo\n",
        "\n",
        "Un aspecto a considerar es la diferencia que puede existir entre los clasificadores y las buenas probabilidades, lo que nos lleva evaluar la calibración de las mismas, que no es otra cosa que el grado de aproximación de las probabilidades previstas versus las probabilidades reales. Sin embargo, esto nos provoca otro problema que tiene que ver con los segmentos o intervalos en que se divide un conjunto de datos, para lo que se ha experimentado superponerlos. \n",
        "\n",
        "Una de las métricas más usadas para evaluar una clasificación es la **precisión**, que es el grado de predicciones correctas de un modelo. \n",
        "\n",
        "\n",
        "**Área Bajo la Curva (AUC)** es otra de las métricas usadas, se define como la probabilidad de que un clasificador clasifique de manera positiva una instancia en vez de una negativa tomadas al azar. \n",
        "\n",
        "**Error Absoluto Medio (MAE)** muestra cuánto se desvian las predicciones de la probabilidad real. \n",
        "\n",
        "**Error Cuadrático Medio (MSE)** es una variante de MAE que penaliza fuertemente las debiaciones de la probabilidad real.\n",
        "\n",
        "Una primera conclusión que se llega en el artículo es que ninguna de las 18 métricas tiene un sí en el umbral de clase y en la calibraación o clasificación, esto es que no hay medida que combine el umbral con la probabilidad estimada. \n",
        "\n",
        "Una segunda conclusión es que al aplicar ruido al conjunto de datos, en este caso la precisión y otras medidas cualitativas son mejores cuando el ruido esta presente en el conjunto de datos. Por el contrario, estas son malas cuando el ruido es aplicado al aprendizaje.\n",
        "\n",
        "Finalmente, se observa que las diferentes métricas no pueden ser comparables, usando las correlaciones se encontró que estas suelen tener desempeño bajo entre las diversas medidas. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "daJsHg6kAme6"
      }
    }
  ]
}