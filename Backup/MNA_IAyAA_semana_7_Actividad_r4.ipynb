{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A01793509/Equipo38/blob/main/MNA_IAyAA_semana_7_Actividad_r4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Adtividad de la Semana 7**\n",
        "###**Red Neuronal Artificial - Perceptrón Multicapa : Multilayer Perceptrón (MLP)**\n"
      ],
      "metadata": {
        "id": "VFj0sSM06dYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nombres y matrículas de los integrantes del equipo:**\n",
        "\n",
        "*   Alberto Jose Garcia Porras (A01793509)\n",
        "*   Carlos Julio León Caicedo (A01793947)\n",
        "*   Luis Fernando Ríos Piedra (A00453954)\n",
        "*   Marco Antonio Vázquez Morales (A01793704)"
      ],
      "metadata": {
        "id": "Qgrvy0RGB9XI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cada sección deberás incluir todas las líneas de código necesarias para responder a cada uno de los ejercicios."
      ],
      "metadata": {
        "id": "FrJ2ahMODVj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Contexto del problema y el conjunto de datos a utilizar**\n",
        "\n",
        "El objetivo es determinar el impacto generado por un anuncio de una marca de cosméticos en Facebook, en el cual se intentaron varias variantes en la manera de mostrar el anuncio. Siguiendo el [artículo](https://www.semanticscholar.org/paper/Predicting-social-media-performance-metrics-and-of-Moro-Rita/dec55692590820754b53c916e29bb2b42c0e5104), deberás considerar como predictores o variables de entrada aquellas que se indican en la Tabla 3. Por otro lado, en la Tabla 2, los autores consideran varios casos para la variable de salida, intentando determinar cuál puede ser el mejor caso para medir el éxito de la campaña. Para este ejercicio deberás considerar únicamente los siguientes tres casos como variable de salida: “Lifetime post consumers”, “Lifetime People who have liked a Page and engaged with a post” y “Likes”. \n",
        "\n",
        "El conjunto de datos a utilizar es el de la siguiente liga de la UCI:\n",
        "https://archive.ics.uci.edu/ml/datasets/Facebook+metrics\n"
      ],
      "metadata": {
        "id": "sxlSJ-k7NYTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incluye aquí todos módulos, librerías y paquetes que requieras.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests, zipfile\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import make_scorer,classification_report\n",
        "from imblearn.metrics import geometric_mean_score, classification_report_imbalanced\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold,RepeatedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from io import BytesIO\n",
        "\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor"
      ],
      "metadata": {
        "id": "exXsscs-Dh-2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X25brD-gQdZM"
      },
      "source": [
        "#**Ejercicio-1.** \n",
        "\n",
        "En esta tarea considera únicamente la siguiente variable de salida que se concluye que es una de las mejores en el artículo antes citado:  ‘Lifetime People who have liked a Page and engaged with a post'. Renombra dicha variable como “LPE”. Como variables de entrada selecciona las 7 variables que indican los autores en la Tabla 3 del artículo citado.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00368/Facebook_metrics.zip'\n",
        "base_datos = path.split('/')[-1]\n",
        "req_path = requests.get(path)\n",
        "\n",
        "archivo_uci= zipfile.ZipFile(BytesIO(req_path.content))\n",
        "archivo_uci.extractall('/content/sample_data/Facebook_metrics')\n",
        "df = pd.read_csv(\"/content/sample_data/Facebook_metrics/dataset_Facebook.csv\",sep=';')\n",
        "\n",
        "df.rename(columns={'Lifetime People who have liked your Page and engaged with your post':'LPE'},\n",
        "               inplace=True)\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "3nU2GuWYCy6C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "da6fb040-cdee-423b-a617-033b42937f3c"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Page total likes   Type  Category  Post Month  Post Weekday  Post Hour  \\\n",
              "495             85093  Photo         3           1             7          2   \n",
              "496             81370  Photo         2           1             5          8   \n",
              "497             81370  Photo         1           1             5          2   \n",
              "498             81370  Photo         3           1             4         11   \n",
              "499             81370  Photo         2           1             4          4   \n",
              "\n",
              "     Paid  Lifetime Post Total Reach  Lifetime Post Total Impressions  \\\n",
              "495   0.0                       4684                             7536   \n",
              "496   0.0                       3480                             6229   \n",
              "497   0.0                       3778                             7216   \n",
              "498   0.0                       4156                             7564   \n",
              "499   NaN                       4188                             7292   \n",
              "\n",
              "     Lifetime Engaged Users  Lifetime Post Consumers  \\\n",
              "495                     733                      708   \n",
              "496                     537                      508   \n",
              "497                     625                      572   \n",
              "498                     626                      574   \n",
              "499                     564                      524   \n",
              "\n",
              "     Lifetime Post Consumptions  \\\n",
              "495                         985   \n",
              "496                         687   \n",
              "497                         795   \n",
              "498                         832   \n",
              "499                         743   \n",
              "\n",
              "     Lifetime Post Impressions by people who have liked your Page  \\\n",
              "495                                               4750              \n",
              "496                                               3961              \n",
              "497                                               4742              \n",
              "498                                               4534              \n",
              "499                                               3861              \n",
              "\n",
              "     Lifetime Post reach by people who like your Page  LPE  comment  like  \\\n",
              "495                                              2876  392        5  53.0   \n",
              "496                                              2104  301        0  53.0   \n",
              "497                                              2388  363        4  93.0   \n",
              "498                                              2452  370        7  91.0   \n",
              "499                                              2200  316        0  91.0   \n",
              "\n",
              "     share  Total Interactions  \n",
              "495   26.0                  84  \n",
              "496   22.0                  75  \n",
              "497   18.0                 115  \n",
              "498   38.0                 136  \n",
              "499   28.0                 119  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a53432f-7f88-4745-b87c-5b06d571e1cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page total likes</th>\n",
              "      <th>Type</th>\n",
              "      <th>Category</th>\n",
              "      <th>Post Month</th>\n",
              "      <th>Post Weekday</th>\n",
              "      <th>Post Hour</th>\n",
              "      <th>Paid</th>\n",
              "      <th>Lifetime Post Total Reach</th>\n",
              "      <th>Lifetime Post Total Impressions</th>\n",
              "      <th>Lifetime Engaged Users</th>\n",
              "      <th>Lifetime Post Consumers</th>\n",
              "      <th>Lifetime Post Consumptions</th>\n",
              "      <th>Lifetime Post Impressions by people who have liked your Page</th>\n",
              "      <th>Lifetime Post reach by people who like your Page</th>\n",
              "      <th>LPE</th>\n",
              "      <th>comment</th>\n",
              "      <th>like</th>\n",
              "      <th>share</th>\n",
              "      <th>Total Interactions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>85093</td>\n",
              "      <td>Photo</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4684</td>\n",
              "      <td>7536</td>\n",
              "      <td>733</td>\n",
              "      <td>708</td>\n",
              "      <td>985</td>\n",
              "      <td>4750</td>\n",
              "      <td>2876</td>\n",
              "      <td>392</td>\n",
              "      <td>5</td>\n",
              "      <td>53.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>81370</td>\n",
              "      <td>Photo</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3480</td>\n",
              "      <td>6229</td>\n",
              "      <td>537</td>\n",
              "      <td>508</td>\n",
              "      <td>687</td>\n",
              "      <td>3961</td>\n",
              "      <td>2104</td>\n",
              "      <td>301</td>\n",
              "      <td>0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>81370</td>\n",
              "      <td>Photo</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3778</td>\n",
              "      <td>7216</td>\n",
              "      <td>625</td>\n",
              "      <td>572</td>\n",
              "      <td>795</td>\n",
              "      <td>4742</td>\n",
              "      <td>2388</td>\n",
              "      <td>363</td>\n",
              "      <td>4</td>\n",
              "      <td>93.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>81370</td>\n",
              "      <td>Photo</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4156</td>\n",
              "      <td>7564</td>\n",
              "      <td>626</td>\n",
              "      <td>574</td>\n",
              "      <td>832</td>\n",
              "      <td>4534</td>\n",
              "      <td>2452</td>\n",
              "      <td>370</td>\n",
              "      <td>7</td>\n",
              "      <td>91.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>81370</td>\n",
              "      <td>Photo</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4188</td>\n",
              "      <td>7292</td>\n",
              "      <td>564</td>\n",
              "      <td>524</td>\n",
              "      <td>743</td>\n",
              "      <td>3861</td>\n",
              "      <td>2200</td>\n",
              "      <td>316</td>\n",
              "      <td>0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a53432f-7f88-4745-b87c-5b06d571e1cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a53432f-7f88-4745-b87c-5b06d571e1cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a53432f-7f88-4745-b87c-5b06d571e1cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Llenado de dato único dato nulo encontrado\n",
        "df['Paid']=df['Paid'].fillna(0)"
      ],
      "metadata": {
        "id": "YoZ9w8BQbzJP"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separación de variables numéricas y categóricas del df original\n",
        "#Creación de dummies para variable Type\n",
        "df_nums = df.select_dtypes(exclude='object')\n",
        "df_objs = df.select_dtypes(include='object')\n",
        "df_objs = pd.get_dummies(df_objs,drop_first=False)\n",
        "final_df = pd.concat([df_nums,df_objs],axis=1)\n",
        "final_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K1WQxbtX2oI",
        "outputId": "ff63a0e1-3971-44cd-db1a-5496b2779ce6"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Page total likes', 'Category', 'Post Month', 'Post Weekday',\n",
              "       'Post Hour', 'Paid', 'Lifetime Post Total Reach',\n",
              "       'Lifetime Post Total Impressions', 'Lifetime Engaged Users',\n",
              "       'Lifetime Post Consumers', 'Lifetime Post Consumptions',\n",
              "       'Lifetime Post Impressions by people who have liked your Page',\n",
              "       'Lifetime Post reach by people who like your Page', 'LPE', 'comment',\n",
              "       'like', 'share', 'Total Interactions', 'Type_Link', 'Type_Photo',\n",
              "       'Type_Status', 'Type_Video'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generar df con variables finales para el modelo\n",
        "var_input=final_df[['Category', 'Page total likes', 'Type_Photo', 'Type_Status',\n",
        "       'Type_Video', 'Post Month', 'Post Hour', 'Post Weekday', 'Paid','LPE']]\n",
        "# print(df[['Category', 'Page total likes', 'Type', 'Post Month', 'Post Hour', 'Post Weekday', 'Paid']])\n"
      ],
      "metadata": {
        "id": "0ulkqXVGCy97"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_input.describe(include='all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "aIeXsS5eOwfP",
        "outputId": "2d0ac862-ce0d-4c1e-df63-30e480225ea3"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Category  Page total likes  Type_Photo  Type_Status  Type_Video  \\\n",
              "count  500.000000        500.000000  500.000000   500.000000  500.000000   \n",
              "mean     1.880000     123194.176000    0.852000     0.090000    0.014000   \n",
              "std      0.852675      16272.813214    0.355456     0.286468    0.117608   \n",
              "min      1.000000      81370.000000    0.000000     0.000000    0.000000   \n",
              "25%      1.000000     112676.000000    1.000000     0.000000    0.000000   \n",
              "50%      2.000000     129600.000000    1.000000     0.000000    0.000000   \n",
              "75%      3.000000     136393.000000    1.000000     0.000000    0.000000   \n",
              "max      3.000000     139441.000000    1.000000     1.000000    1.000000   \n",
              "\n",
              "       Post Month   Post Hour  Post Weekday        Paid          LPE  \n",
              "count  500.000000  500.000000    500.000000  500.000000   500.000000  \n",
              "mean     7.038000    7.840000      4.150000    0.278000   609.986000  \n",
              "std      3.307936    4.368589      2.030701    0.448462   612.725618  \n",
              "min      1.000000    1.000000      1.000000    0.000000     9.000000  \n",
              "25%      4.000000    3.000000      2.000000    0.000000   291.000000  \n",
              "50%      7.000000    9.000000      4.000000    0.000000   412.000000  \n",
              "75%     10.000000   11.000000      6.000000    1.000000   656.250000  \n",
              "max     12.000000   23.000000      7.000000    1.000000  4376.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b387ceb-405b-4302-83a8-7f56569908fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Page total likes</th>\n",
              "      <th>Type_Photo</th>\n",
              "      <th>Type_Status</th>\n",
              "      <th>Type_Video</th>\n",
              "      <th>Post Month</th>\n",
              "      <th>Post Hour</th>\n",
              "      <th>Post Weekday</th>\n",
              "      <th>Paid</th>\n",
              "      <th>LPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.880000</td>\n",
              "      <td>123194.176000</td>\n",
              "      <td>0.852000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>7.038000</td>\n",
              "      <td>7.840000</td>\n",
              "      <td>4.150000</td>\n",
              "      <td>0.278000</td>\n",
              "      <td>609.986000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.852675</td>\n",
              "      <td>16272.813214</td>\n",
              "      <td>0.355456</td>\n",
              "      <td>0.286468</td>\n",
              "      <td>0.117608</td>\n",
              "      <td>3.307936</td>\n",
              "      <td>4.368589</td>\n",
              "      <td>2.030701</td>\n",
              "      <td>0.448462</td>\n",
              "      <td>612.725618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>81370.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>112676.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>291.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>129600.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>412.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>136393.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>656.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>139441.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4376.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b387ceb-405b-4302-83a8-7f56569908fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b387ceb-405b-4302-83a8-7f56569908fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b387ceb-405b-4302-83a8-7f56569908fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AwropDGy9QK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos los atributos de entrada como 'X' y a la variable de salida como 'Y'\n",
        "# Para este ejercicio deberás considerar únicamente los siguientes tres casos como variable de salida: \n",
        "# “Lifetime post consumers”, “Lifetime People who have liked a Page and engaged with a post” y “Likes”.\n",
        "\n",
        "X = var_input.drop('LPE',axis=1)\n",
        "y = var_input['LPE']\n",
        "\n",
        "#Variables de salida de la Tabla 2, los autores consideran varios casos para la variable de salida\n",
        "# Y=df['Lifetime post total reach','Lifetime post total impressions','Lifetime engaged users','Lifetime post consumers',\n",
        "#      'Lifetime post consumotions','Lifetime post impressions by people who have liked a page','Lifetime post reach by people who like a page'\n",
        "#      'Lifetime people who have liked a page and engaged with a post','Comments','Likes','Shares','Total interactions']"
      ],
      "metadata": {
        "id": "gOJhhc8dZ1UP"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_input.columns\n"
      ],
      "metadata": {
        "id": "C1Rw4YhD4Ddr",
        "outputId": "888923c1-41b4-4321-9259-c8ad50db5b26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Category', 'Page total likes', 'Type_Photo', 'Type_Status',\n",
              "       'Type_Video', 'Post Month', 'Post Hour', 'Post Weekday', 'Paid', 'LPE'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "e3k8QL-SAhI1",
        "outputId": "5c9460a9-d29c-4f2f-8a5e-79fb7bd5c022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Page total likes  Category  Type_Photo  Type_Status  Type_Video  \\\n",
              "0            2.000000       2.0         1.0          0.0         0.0   \n",
              "1            2.000000       2.0         0.0          1.0         0.0   \n",
              "2            2.000000       3.0         1.0          0.0         0.0   \n",
              "3            2.000000       2.0         1.0          0.0         0.0   \n",
              "4            2.000000       2.0         1.0          0.0         0.0   \n",
              "..                ...       ...         ...          ...         ...   \n",
              "495          1.064111       3.0         1.0          0.0         0.0   \n",
              "496          1.000000       2.0         1.0          0.0         0.0   \n",
              "497          1.000000       1.0         1.0          0.0         0.0   \n",
              "498          1.000000       3.0         1.0          0.0         0.0   \n",
              "499          1.000000       2.0         1.0          0.0         0.0   \n",
              "\n",
              "     Post Month  Post Hour  Post Weekday  Paid  Type_Photo_2  Type_Status_2  \\\n",
              "0          12.0        3.0           4.0   0.0           1.0            0.0   \n",
              "1          12.0       10.0           3.0   0.0           0.0            1.0   \n",
              "2          12.0        3.0           3.0   0.0           1.0            0.0   \n",
              "3          12.0       10.0           2.0   1.0           1.0            0.0   \n",
              "4          12.0        3.0           2.0   0.0           1.0            0.0   \n",
              "..          ...        ...           ...   ...           ...            ...   \n",
              "495         1.0        2.0           7.0   0.0           1.0            0.0   \n",
              "496         1.0        8.0           5.0   0.0           1.0            0.0   \n",
              "497         1.0        2.0           5.0   0.0           1.0            0.0   \n",
              "498         1.0       11.0           4.0   0.0           1.0            0.0   \n",
              "499         1.0        4.0           4.0   0.0           1.0            0.0   \n",
              "\n",
              "     Type_Video_2  Paid_2  \n",
              "0             0.0     0.0  \n",
              "1             0.0     0.0  \n",
              "2             0.0     0.0  \n",
              "3             0.0     1.0  \n",
              "4             0.0     0.0  \n",
              "..            ...     ...  \n",
              "495           0.0     0.0  \n",
              "496           0.0     0.0  \n",
              "497           0.0     0.0  \n",
              "498           0.0     0.0  \n",
              "499           0.0     0.0  \n",
              "\n",
              "[500 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0bc30a7-bd2b-4aef-bb0b-25008452b390\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page total likes</th>\n",
              "      <th>Category</th>\n",
              "      <th>Type_Photo</th>\n",
              "      <th>Type_Status</th>\n",
              "      <th>Type_Video</th>\n",
              "      <th>Post Month</th>\n",
              "      <th>Post Hour</th>\n",
              "      <th>Post Weekday</th>\n",
              "      <th>Paid</th>\n",
              "      <th>Type_Photo_2</th>\n",
              "      <th>Type_Status_2</th>\n",
              "      <th>Type_Video_2</th>\n",
              "      <th>Paid_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1.064111</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0bc30a7-bd2b-4aef-bb0b-25008452b390')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0bc30a7-bd2b-4aef-bb0b-25008452b390 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0bc30a7-bd2b-4aef-bb0b-25008452b390');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "cVFQdyRSAkGZ",
        "outputId": "72d9d657-5064-4c6d-db4a-b218b3ba190a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1.025189\n",
              "1      1.251660\n",
              "2      1.028166\n",
              "3      1.315319\n",
              "4      1.088619\n",
              "         ...   \n",
              "495    1.087703\n",
              "496    1.066865\n",
              "497    1.081063\n",
              "498    1.082665\n",
              "499    1.070300\n",
              "Name: LPE, Length: 500, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-2.**\n",
        "\n",
        "Realiza una partición de los datos con 100 datos de Prueba y el resto para entrenamiento y validación."
      ],
      "metadata": {
        "id": "xZhr2hkECzVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Definimos los atributos de entrada como 'X' y a la variable de salida como 'Y'\n",
        "# # Para este ejercicio deberás considerar únicamente los siguientes tres casos como variable de salida: \n",
        "# # “Lifetime post consumers”, “Lifetime People who have liked a Page and engaged with a post” y “Likes”.\n",
        "\n",
        "# var_otput = ['LPE']\n",
        "# X = df[var_input]\n",
        "# Y = df[var_otput]\n",
        "\n",
        "# #Variables de salida de la Tabla 2, los autores consideran varios casos para la variable de salida\n",
        "# # Y=df['Lifetime post total reach','Lifetime post total impressions','Lifetime engaged users','Lifetime post consumers',\n",
        "# #      'Lifetime post consumotions','Lifetime post impressions by people who have liked a page','Lifetime post reach by people who like a page'\n",
        "# #      'Lifetime people who have liked a page and engaged with a post','Comments','Likes','Shares','Total interactions']"
      ],
      "metadata": {
        "id": "kGfAoOPkC1PP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Partición de datos, test_size=100*100/500= 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20)\n"
      ],
      "metadata": {
        "id": "GOydw5OGC1MJ"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_testt=X_test.reset_index().drop('index', axis='columns') \n",
        "y_testt=y_test.reset_index().drop('index', axis='columns') "
      ],
      "metadata": {
        "id": "n45H1kF3SFtX"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ravel(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSACJ_P3i6bU",
        "outputId": "da00f595-fb0d-4c42-daa9-aebd861e1d97"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2126,  168,  762,  306,  167, 1834,  157,  403,  230,  391,  297,\n",
              "        347, 1292,  293,  333, 1275, 1613,  814,  140,  340, 2119,  508,\n",
              "       1200,  621,  705,  732, 1578,  477,  269,  630,  305,  559,  316,\n",
              "        123,  152, 3430,  436, 1513,  342,  278,  435,  475, 2278,  985,\n",
              "         59,  998, 1542,  119,  437,  646,  395, 1101,  340, 2256,  283,\n",
              "        220,  393,  327,  319,   32,  240,  699,  413,  220,  471,  379,\n",
              "        305,    9,  301,  576,  441,  275, 1779, 1276,  422,  287, 1146,\n",
              "        240,  348,  456,   93,  375,  327,  392,  414,  392,  557,  100,\n",
              "        289, 1356,  348,  300, 1086,  774,  563,   58, 1564,  465,  335,\n",
              "        482,  236, 3798,  884,  885,  774, 1331,   92,  606,  156,  399,\n",
              "        476,  248, 2342,  475,  447,  357,  327,  697,  594,  106, 1052,\n",
              "        126,  363,  211,  590,  134,  462,  185, 1661,  403,  514,  447,\n",
              "        268,  319,  569,  760,  291, 1233,  363,  236,  740,  375, 2252,\n",
              "        907, 3316,  131,  408,  924, 3300,  347, 1353,  516, 1609,  408,\n",
              "         15,  740,  196,  642,  181, 1392,  351,  584,  460,  454,  323,\n",
              "       1292,  323,  176, 1905,  101,  309,  397,  604,  246,  445,   15,\n",
              "        470,  660,  788,  367,  981, 4318,  630,  530,  363,  537,  361,\n",
              "        684,  123,  398,  239,  493,  382,  453,  244,  387,  263,  621,\n",
              "        463,  351,   93,  428,  404,  277,  440,  132,  461,  183,  656,\n",
              "        432,  280,  351,  143,  408, 1035,  180,  459,  570,  390,  361,\n",
              "        489, 2806,  593,   77, 1185,  315, 1349,  393,   33,  398,  401,\n",
              "        287,  650, 1975,  165,  497,  459,  340,  471,  505,  389,  266,\n",
              "        538,  438,  537,  307,  724,  796,  191, 1395,  365,  298, 1354,\n",
              "        501,  377,  360,  166,  484, 1978,  175,  253,  389,  977,  428,\n",
              "        346,  379,  316,  429,  355,  328,  251,  306, 1075, 1604,  436,\n",
              "        187,  488,  166,  259,  598,  995,  169, 1756,  154,  143,  271,\n",
              "        248, 1225, 2099,  314, 1250,  559,  385,   17,  361,  348,  467,\n",
              "        309,  920, 2602, 1307,  460, 1162,  483,  237,  729,  583,  431,\n",
              "        448,  137, 2361,  469,  708,  504,  801, 1008,  355,  262, 1790,\n",
              "        403,  175,  252,  439,  497,  194, 4376,  375,  222,  280,  288,\n",
              "        865,  305,  341,  194,  232,  506, 1020,  570,  340,  583,  487,\n",
              "       1716,  445,  316, 3014,  546,  280, 4104,  876,  742,  268, 1034,\n",
              "        555,  384,  345,  662,  349,  403,  446,  432,  706,  289,  265,\n",
              "        233,  497,  341,  505,  563,  221,  441,  636,   99,  843,  200,\n",
              "        328,  628,  701,  389,  757,  722,  440,  370,  472,  975,  583,\n",
              "        199,  422,  492,  322,  342,  279,  420,  705, 1936,  469,  704,\n",
              "       1016,  392,  411,  403])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-3.**\n",
        "Definirás tus propias funciones de errores para este problema de regresión. Los errores que utilizarás son la raíz cuadrada del error cuadrático medio RMSE, el error absoluto medio MAE y el error porcentual absoluto medio MAPE."
      ],
      "metadata": {
        "id": "NCunuooTC2W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Definiendo función RMSE\n",
        "def mi_RMSE(y_val,yhatVal):\n",
        "  return np.mean(np.sqrt(np.abs(y_val-yhatVal)))\n",
        "#Definiendo función MAE\n",
        "def mi_MAE(y_val,yhatVal):\n",
        "  return np.mean(np.abs(y_val-yhatVal))\n",
        "#Definiendo función MAPE\n",
        "def mi_MAPE(y_val,yhatVal):\n",
        "  return np.mean(np.abs((y_val-yhatVal)/y_val))*100"
      ],
      "metadata": {
        "id": "YXlcSWA-C4Dj"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-4.**\n",
        "En la página de la UCI, así como en el artículo de los autores previamente citado encuentras información en relación al significado de cada variable. Haz una análisis de tus datos y lleva a cabo las transformaciones que consideres adecuadas tanto en los datos de entrada, como en las de salida.\n",
        "Utiliza un Pipeline para evitar el filtrado de información.\n"
      ],
      "metadata": {
        "id": "chqk9jIDC5Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones a factores numéricos de entrada:\n",
        "num_pipe = Pipeline(steps = [('impMediana', SimpleImputer(strategy='median')),\n",
        "                                 ('escalaNum', MinMaxScaler(feature_range=(1,2)))])   \n",
        "num_pipe_nombres = [ 'Page total likes', 'LPE']\n",
        "\n",
        "# Transformaciones a factores categóricos de entrada:\n",
        "catImp_pipe = Pipeline(steps = [('impModa', SimpleImputer(strategy='most_frequent'))])  \n",
        "catImp_pipe_nombres = ['Category', 'Type_Photo', 'Type_Status',\n",
        "       'Type_Video', 'Post Month', 'Post Hour', 'Post Weekday','Paid']\n",
        "\n",
        "catOHE_pipe = Pipeline(steps = [('OneHotE', OneHotEncoder(drop='first',handle_unknown='ignore'))])\n",
        "catOHE_pipe_nombres = ['Type_Photo', 'Type_Status',\n",
        "       'Type_Video','Paid']\n",
        "\n",
        "# Conjuntamos las transformaciones numéricas y categóricas que se estarán aplicando a los datos de entrada:\n",
        "columnasTransformer = ColumnTransformer(transformers = [('numpipe', num_pipe, num_pipe_nombres),\n",
        "                                                        ('catimp', catImp_pipe, catImp_pipe_nombres),\n",
        "                                                        ('catohe', catOHE_pipe, catOHE_pipe_nombres)],\n",
        "                                        remainder='passthrough')\n",
        "\n",
        "pipe = Pipeline(steps=[('ct',columnasTransformer)])"
      ],
      "metadata": {
        "id": "RBVSFwK4C6g9"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones a factores numéricos de entrada:\n",
        "num_pipe = Pipeline(steps = [('impMediana', SimpleImputer(strategy='median')),\n",
        "                                 ('escalaNum', MinMaxScaler(feature_range=(1,2)))])   \n",
        "num_pipe_nombres = [ 'Page total likes']\n",
        "\n",
        "# Transformaciones a factores categóricos de entrada:\n",
        "catImp_pipe = Pipeline(steps = [('impModa', SimpleImputer(strategy='most_frequent'))])  \n",
        "catImp_pipe_nombres = ['Category', 'Type_Photo', 'Type_Status',\n",
        "       'Type_Video', 'Post Month', 'Post Hour', 'Post Weekday','Paid']\n",
        "\n",
        "catOHE_pipe = Pipeline(steps = [('OneHotE', OneHotEncoder(drop='first',handle_unknown='ignore'))])\n",
        "catOHE_pipe_nombres = ['Type_Photo', 'Type_Status',\n",
        "       'Type_Video','Paid']\n",
        "\n",
        "# Conjuntamos las transformaciones numéricas y categóricas que se estarán aplicando a los datos de entrada:\n",
        "columnasTransformer = ColumnTransformer(transformers = [('numpipe', num_pipe, num_pipe_nombres),\n",
        "                                                        ('catimp', catImp_pipe, catImp_pipe_nombres),\n",
        "                                                        ('catohe', catOHE_pipe, catOHE_pipe_nombres)],\n",
        "                                        remainder='passthrough')"
      ],
      "metadata": {
        "id": "C-08lIAiBDlr"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(var_input)\n",
        "\n",
        "var_input=pipe.transform(var_input)\n",
        "\n",
        "var_input_df = pd.DataFrame(var_input)\n"
      ],
      "metadata": {
        "id": "JOxF8Q-10yW0"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_input_df.columns=['Page total likes', 'LPE', 'Category','Type_Photo', 'Type_Status','Type_Video', 'Post Month','Post Hour', 'Post Weekday','Paid', 'Type_Photo_2', 'Type_Status_2', 'Type_Video_2', 'Paid_2']"
      ],
      "metadata": {
        "id": "rm2g2U3k4kmh"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_input=var_input_df"
      ],
      "metadata": {
        "id": "e2itivs946sP"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_input_df.columns='Category', 'Page total likes', 'Type_Photo', 'Type_Status',\n",
        "       'Type_Video', 'Post Month', 'Post Hour', 'Post Weekday', 'Paid', 'LPE'],\n",
        "      dtype='object'"
      ],
      "metadata": {
        "id": "e-rlrSYZ5OVL",
        "outputId": "f782de99-424c-4c94-aa10-9d853680faf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Page total likes       LPE  Category  Page total likes  Type_Photo  \\\n",
              "0            2.000000  1.025189       2.0          139441.0         1.0   \n",
              "1            2.000000  1.251660       2.0          139441.0         0.0   \n",
              "2            2.000000  1.028166       3.0          139441.0         1.0   \n",
              "3            2.000000  1.315319       2.0          139441.0         1.0   \n",
              "4            2.000000  1.088619       2.0          139441.0         1.0   \n",
              "..                ...       ...       ...               ...         ...   \n",
              "495          1.064111  1.087703       3.0           85093.0         1.0   \n",
              "496          1.000000  1.066865       2.0           81370.0         1.0   \n",
              "497          1.000000  1.081063       1.0           81370.0         1.0   \n",
              "498          1.000000  1.082665       3.0           81370.0         1.0   \n",
              "499          1.000000  1.070300       2.0           81370.0         1.0   \n",
              "\n",
              "     Type_Status  Type_Video  Post Month  Post Hour  Post Weekday  Paid  \\\n",
              "0            0.0         0.0        12.0        3.0           4.0   0.0   \n",
              "1            1.0         0.0        12.0       10.0           3.0   0.0   \n",
              "2            0.0         0.0        12.0        3.0           3.0   0.0   \n",
              "3            0.0         0.0        12.0       10.0           2.0   1.0   \n",
              "4            0.0         0.0        12.0        3.0           2.0   0.0   \n",
              "..           ...         ...         ...        ...           ...   ...   \n",
              "495          0.0         0.0         1.0        2.0           7.0   0.0   \n",
              "496          0.0         0.0         1.0        8.0           5.0   0.0   \n",
              "497          0.0         0.0         1.0        2.0           5.0   0.0   \n",
              "498          0.0         0.0         1.0       11.0           4.0   0.0   \n",
              "499          0.0         0.0         1.0        4.0           4.0   0.0   \n",
              "\n",
              "     Type_Photo_2  Type_Status_2  Type_Video_2  Paid_2  \n",
              "0             1.0            0.0           0.0     0.0  \n",
              "1             0.0            1.0           0.0     0.0  \n",
              "2             1.0            0.0           0.0     0.0  \n",
              "3             1.0            0.0           0.0     1.0  \n",
              "4             1.0            0.0           0.0     0.0  \n",
              "..            ...            ...           ...     ...  \n",
              "495           1.0            0.0           0.0     0.0  \n",
              "496           1.0            0.0           0.0     0.0  \n",
              "497           1.0            0.0           0.0     0.0  \n",
              "498           1.0            0.0           0.0     0.0  \n",
              "499           1.0            0.0           0.0     0.0  \n",
              "\n",
              "[500 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff912c6f-b7a8-4c4d-b65e-21d27e95f7b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page total likes</th>\n",
              "      <th>LPE</th>\n",
              "      <th>Category</th>\n",
              "      <th>Page total likes</th>\n",
              "      <th>Type_Photo</th>\n",
              "      <th>Type_Status</th>\n",
              "      <th>Type_Video</th>\n",
              "      <th>Post Month</th>\n",
              "      <th>Post Hour</th>\n",
              "      <th>Post Weekday</th>\n",
              "      <th>Paid</th>\n",
              "      <th>Type_Photo_2</th>\n",
              "      <th>Type_Status_2</th>\n",
              "      <th>Type_Video_2</th>\n",
              "      <th>Paid_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.025189</td>\n",
              "      <td>2.0</td>\n",
              "      <td>139441.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.251660</td>\n",
              "      <td>2.0</td>\n",
              "      <td>139441.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.028166</td>\n",
              "      <td>3.0</td>\n",
              "      <td>139441.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.315319</td>\n",
              "      <td>2.0</td>\n",
              "      <td>139441.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.088619</td>\n",
              "      <td>2.0</td>\n",
              "      <td>139441.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1.064111</td>\n",
              "      <td>1.087703</td>\n",
              "      <td>3.0</td>\n",
              "      <td>85093.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.066865</td>\n",
              "      <td>2.0</td>\n",
              "      <td>81370.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.081063</td>\n",
              "      <td>1.0</td>\n",
              "      <td>81370.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.082665</td>\n",
              "      <td>3.0</td>\n",
              "      <td>81370.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.070300</td>\n",
              "      <td>2.0</td>\n",
              "      <td>81370.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff912c6f-b7a8-4c4d-b65e-21d27e95f7b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff912c6f-b7a8-4c4d-b65e-21d27e95f7b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff912c6f-b7a8-4c4d-b65e-21d27e95f7b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-5.**\n",
        "Utiliza la función Dummy para modelos de regresión de scikit-learn con el conjunto que tienes de datos de entrenamiento y validación. Para ello particiónalos en 100 para validación y 300 para entrenamiento. Encuentra los errores RMSE, MAE y MAPE para los conjuntos de entrenamiento y validación. \n",
        "\n",
        "Estos serán tus errores máximos que deberás tomar como referencia en el resto de la actividad. Consulta su documentación correspondiente: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html"
      ],
      "metadata": {
        "id": "Rv7KFq-mC7PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Partición de datos, test_size=100*100/400= 25%\n",
        "Xtrain, X_val, ytrain, y_val = train_test_split(X_train, y_train, test_size=.25)"
      ],
      "metadata": {
        "id": "jaDj3kawC9B6"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "modeloDummy = DummyRegressor(strategy=\"mean\")\n",
        "\n",
        "XtrainFit_d = columnasTransformer.fit(Xtrain)   \n",
        "XtrainTransf_d = XtrainFit_d.transform(Xtrain) \n",
        "\n",
        "modeloDummy=modeloDummy.fit(XtrainTransf_d, ytrain)\n",
        "\n",
        "XvalTransf_d = XtrainFit_d.transform(X_val)\n",
        "yhat = modeloDummy.predict(XvalTransf_d)\n",
        "\n",
        "#modeloDummy.score(X_train,y_train)\n",
        "\n",
        "print('Valor de RMSE a superar: %.4f' % np.mean(mi_RMSE(y_val,yhat)))\n",
        "print(\"Valor del MAE a superar: %.4f\" % np.mean(mi_MAE(y_val,yhat)))\n",
        "print(\"Valor del MAPE a superar: %.4f\" % np.mean(mi_MAPE(y_val,yhat)))"
      ],
      "metadata": {
        "id": "4tQxQROVC9Us",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae71a44-d29b-48a4-e3dd-c14895e6115b"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor de RMSE a superar: 0.2637\n",
            "Valor del MAE a superar: 0.0834\n",
            "Valor del MAPE a superar: 6.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-6.**\n",
        "Usando los modelos de regresión lineal múltiple, el bosque aleatorio y el perceptrón multicapa con sus valores predeterminados, lleva a cabo su entrenamiento con repeticiones de validación cruzada (RepeatedKFold) y desplegando los errores RMSE, MAE y MAPE. Recuerda evitar el filtrado de\n",
        "información usando los datos que obtuviste en el ejercicio 2. Incluye las conclusiones sobre el mejor modelo encontrado en esta primera aproximación. En particular ¿hay alguno sobreentrenado o subentrenado? NOTA: Recuerda que puedes aumentar en dado caso el número máximo de iteraciones para que todos los modelos converjan."
      ],
      "metadata": {
        "id": "W2S7LI0NC9wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models():\n",
        "  modelos = list()\n",
        "  nombres = list()\n",
        "\n",
        "  # LR - Regresión Lineal Multiiple:\n",
        "  modelos.append(LinearRegression())\n",
        "  nombres.append('LLM')\n",
        "\n",
        "  # DT - Bosque Aleatorio:\n",
        "  modelos.append(RandomForestClassifier())\n",
        "  nombres.append('RF')\n",
        "  \n",
        "  # MLP - Red Neuronal Artificial / Perceptrón Lineal Multicapa:  \n",
        "  modelos.append(MLPClassifier( max_iter=3000))\n",
        "  nombres.append('MLP')\n",
        "  #modelos.append(MLPRegressor(max_iter=3000))\n",
        "  #nombres.append('MLP')\n",
        "  \n",
        "  return modelos, nombres"
      ],
      "metadata": {
        "id": "x6uBleJUC_AU"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "⚠ **¿Es el MLPClassifier o el MLPRegressor?**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TjZBr0_aXd9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelos, nombres = get_models()\n",
        "\n",
        "scores_RMSEVal = list()\n",
        "scores_MAEVal = list()\n",
        "scores_MAPEVal = list()\n",
        "\n",
        "resultados=list()\n",
        "\n",
        "kf = RepeatedKFold(n_splits=5, n_repeats=3,random_state=101) \n",
        "\n",
        "  \n",
        "for i in range(len(modelos)):\n",
        "\n",
        "  pipeline=Pipeline(steps=[('ct',columnasTransformer),('m',modelos[i])])\n",
        "\n",
        "  for train_index, test_index in kf.split(X_test):\n",
        "    \n",
        "    X__train, X__val = X_testt.loc[train_index], X_testt.loc[test_index]\n",
        "    y__train, y__val = y_testt[train_index], y_testt[test_index]\n",
        "  \n",
        "    pipeline.fit(X__train,np.ravel(y__train))\n",
        "    yhatVal=pipeline.predict(X__val)\n",
        "\n",
        "    scores_RMSEVal.append(mi_RMSE(np.ravel(y__val), yhatVal))\n",
        "    scores_MAEVal.append(mi_MAE(np.ravel(y__val), yhatVal))\n",
        "    scores_MAPEVal.append(mi_MAPE(np.ravel(y__val), yhatVal))\n",
        "    \n",
        "  resultados.append(scores_MAPEVal)\n",
        "  # Desplegar información:\n",
        "  print('>> %s:\\nRMSE: %.3f \\nMAE: %.3f  \\nMAPE: %.3f' % (nombres[i],\n",
        "                                                                 np.mean(scores_RMSEVal),\n",
        "                                                                 np.mean(scores_MAEVal),\n",
        "                                                                 np.mean(scores_MAPEVal)))\n",
        "  "
      ],
      "metadata": {
        "id": "n0P_AcyjC_Dh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "762bfa20-a4b6-4b80-85cc-2067adb49df5"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-207-23aaaef9ee4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mX__train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX__val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_testt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_testt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0my__train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my__val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_testt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_testt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my__train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([ 0,  2,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20,\\n            22, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 42, 44,\\n            46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65,\\n            66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85,\\n            86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99],\\n           dtype='int64')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-7.**\n",
        "Obtener los diagramas de caja y bigote para los errores MAPE de los conjuntos de validación obtenidos. En particular compara estos primeros resultados de MAPE con el mejor resultado que encuentran los autores del artículo citado al inicio. Incluye tus conclusiones."
      ],
      "metadata": {
        "id": "iCNGx4TQ8CFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(8,4)})\n",
        "\n",
        "plt.boxplot(np.array(resultados).transpose(),labels=nombres)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ewvwUcJX78y1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "6a28d08a-3486-4f61-b5dd-38c6a87e10b1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-8.**\n",
        "\n",
        "Usando una búsqueda de malla con validación cruzada (GridSearchCV), busca los mejores hiperparámetros para el modelo MLP. Al menos deberás realizar la búsqueda en los hiperparámetros “hidden_layer_sizes”, “alpha” y “learning_rate_init”. Además aplica la validación cruzada con repeticiones (RepeatedKFold). Muestra los mejores hiperparámetros encontrados."
      ],
      "metadata": {
        "id": "tzQn5NR78GFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XtrainTf = columnasTransformer.fit(X_train)\n",
        "XtrainFTf = XtrainTf.transform(X_train)   \n",
        "XtestFTf = XtrainTf.transform(X_test)\n",
        "\n",
        "modelo_MLP=MLPClassifier(max_iter=3000)\n",
        "\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=3)\n",
        "grid_model_MLP = GridSearchCV(modelo_MLP,param_grid={\"alpha\": [0.0001, 0.001, 0.01, 0.1], \"hidden_layer_sizes\": [(10,30,10),(20,)], \"learning_rate_init\": np.linspace(0.00001, 1, 10)},cv=cv,scoring=make_scorer(mi_MAPE), n_jobs=-1)\n",
        "#\"hidden_layer_sizes\":np.arange(1,5),\n",
        "grid_model_MLP.fit(XtrainFTf,y_train)\n",
        "\n",
        "print(\"Utilizando la métrica\", grid_model_MLP.scoring, \"la mejor puntuación obtenida es:\", grid_model_MLP.best_score_)\n",
        "print(\"Los mejores hiperparámetros encontrados son:\", grid_model_MLP.best_params_)\n"
      ],
      "metadata": {
        "id": "FnuXHIJYH4yA",
        "outputId": "21664ca5-93f9-4b27-889a-2d8c6d8344c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "1200 fits failed out of a total of 1200.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.08106251, 1.2441035 ,\n",
            "       1.11609801, 1.02518892, 1.13304328, 1.07098695, 1.06686512,\n",
            "       1.06411724, 1.05381269, 1.04076025, 1.01923517, 1.07465079,\n",
            "       1.20036638, 1.22647126, 1.04350813, 1.0604534 , 1.04236318,\n",
            "       1.08770323, 1.09319899, 1.05381269, 1.12525761, 1.03068468,\n",
            "       1.15754523, 1.08793222, 1.01144951, 1.09457293, 1.4000458 ,\n",
            "       1.10968628, 1.20563316, 1.18433707, 1.09983971, 1.30799176,\n",
            "       1.2466224 , 1.03801237, 1.11564003, 1.02999771, 1.06411724,\n",
            "       1.10487749, 1.05885047, 1.0883902 , 1.2603618 , 1.14220289,\n",
            "       1.16006412, 1.17128463, 1.10579345, 1.05930845, 1.10373254,\n",
            "       1.11380811, 1.02953973, 1.51957866, 1.04373712, 1.25166018,\n",
            "       1.1673918 , 1.21685368, 1.05541562, 1.18021525, 1.16326998,\n",
            "       1.00526677, 1.00549576, 1.07716968, 1.08701626, 1.05793451,\n",
            "       1.08106251, 1.07190291, 1.40531257, 1.45088161, 1.30272498,\n",
            "       1.06778109, 1.13464621, 1.14014197, 1.09022212, 1.11357912,\n",
            "       1.04030227, 1.75727044, 1.1348752 , 1.09411495, 1.22120449,\n",
            "       1.08197847, 1.10029769, 1.0977788 , 1.03595145, 1.1209068 ,\n",
            "       1.09800779, 1.10052668, 1.02610488, 1.07007099, 1.28028395,\n",
            "       1.0790016 , 1.29013052, 1.37829173, 1.06365926, 1.06388825,\n",
            "       1.04167621, 1.10121365, 1.05289673, 1.17242959, 1.07167392,\n",
            "       1.07739867, 1.78337531, 1.08541333, 1.31302954, 1.29379437,\n",
            "       1.03755439, 1.07304786, 1.07098695, 1.08884818, 1.0487749 ,\n",
            "       1.10350355, 1.03366155, 1.13144035, 1.03938631, 1.07098695,\n",
            "       1.19601557, 1.06091138, 1.07579574, 1.30776277, 1.35104191,\n",
            "       1.05724754, 1.05060682, 1.07968857, 1.03595145, 1.19853446,\n",
            "       1.03801237, 1.03366155, 1.16372796, 1.30844974, 1.09892375,\n",
            "       1.08037554, 1.86764369, 1.28990153, 1.0208381 , 1.10716739,\n",
            "       1.09686283, 1.05472865, 1.15800321, 1.10670941, 1.07281887,\n",
            "       1.08564232, 1.05472865, 1.01122052, 1.09663384, 1.15937715,\n",
            "       1.10579345, 1.07602473, 1.00137394, 1.07625372, 1.0767117 ,\n",
            "       1.06205633, 1.11060224, 1.11518205, 1.03640943, 1.0370964 ,\n",
            "       1.02060911, 1.10441951, 1.36730021, 1.08861919, 1.04488207,\n",
            "       1.35699565, 1.09480192, 1.09045111, 1.03572246, 1.07029998,\n",
            "       1.27845203, 1.25051523, 1.14815663, 1.06778109, 1.1069384 ,\n",
            "       1.12846348, 1.03389054, 1.09892375, 1.07923059, 1.22578429,\n",
            "       1.18731395, 1.12892146, 1.2905885 , 1.07281887, 1.07029998,\n",
            "       1.13144035, 1.46072819, 1.07419281, 1.1046485 , 1.11678498,\n",
            "       1.0581635 , 1.06182734, 1.48477215, 1.09274101, 1.13166934,\n",
            "       1.16487291, 1.03320357, 1.23150905, 1.01557133, 1.05266774,\n",
            "       1.08770323, 1.17197161, 1.08266545, 1.07831463, 1.04831692,\n",
            "       1.04236318, 1.09594687, 1.11128921, 1.06686512, 1.08037554,\n",
            "       1.31531944, 1.53858484, 1.15136249, 1.25005725, 1.04465308,\n",
            "       1.09823678, 1.14586673, 1.20861003, 1.069842  , 1.12960843,\n",
            "       1.12686054, 1.08312343, 1.01923517, 1.05129379, 1.03824136,\n",
            "       1.68811541, 1.14586673, 1.02931074, 1.09869476, 1.15456835,\n",
            "       1.04282116, 1.0558736 , 1.17838333, 1.08770323, 1.08152049,\n",
            "       1.08060453, 1.05564461, 1.26402565, 1.02404397, 1.0373254 ,\n",
            "       1.08403939, 1.10533547, 1.12983742, 1.07281887, 1.02106709,\n",
            "       1.05885047, 1.15960614, 1.16784978, 1.11174719, 1.41905198,\n",
            "       1.10602244, 1.10854133, 1.75360659, 1.07579574, 1.04831692,\n",
            "       1.09983971, 1.51454087, 1.07579574, 1.09663384, 1.93771468,\n",
            "       1.09113808, 1.06457522, 1.16670483, 1.07785665, 1.13624914,\n",
            "       1.14014197, 1.09022212, 1.08106251, 1.20952599, 1.04854591,\n",
            "       1.12502862, 1.10945729, 1.08587131, 1.09800779, 1.13373025,\n",
            "       1.11426609, 1.50583925, 1.12594458, 1.0838104 , 1.17151362,\n",
            "       1.08655828, 1.03984429, 1.05953744, 1.36523929, 1.13144035,\n",
            "       1.01900618, 1.08426838, 1.07487978, 1.22349439, 1.19097779,\n",
            "       1.35607969, 1.64048546, 1.1254866 , 1.1023586 , 1.01534234,\n",
            "       1.11174719, 1.08655828, 1.06457522, 1.02862377, 1.29722922,\n",
            "       1.04396611, 1.14838562, 1.08747424, 1.06617815, 1.0861003 ,\n",
            "       1.0022899 , 1.12594458, 1.23471491, 1.35928555, 1.44126403,\n",
            "       1.0861003 , 1.13395924, 1.07762766, 1.12823449, 1.11083123,\n",
            "       1.03274559, 1.06365926, 1.10327456, 1.10831234, 1.1000687 ,\n",
            "       1.05862148, 1.07373483, 1.08701626, 1.0396153 , 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.08106251, 1.2441035 ,\n",
            "       1.06801008, 1.13304328, 1.06686512, 1.06411724, 1.05381269,\n",
            "       1.07762766, 1.04076025, 1.01923517, 1.20036638, 1.22647126,\n",
            "       1.04350813, 1.0604534 , 1.04236318, 1.08770323, 1.09319899,\n",
            "       1.05381269, 1.12525761, 1.12296771, 1.15754523, 1.08793222,\n",
            "       1.06869705, 1.01144951, 1.09457293, 1.4000458 , 1.10968628,\n",
            "       1.12686054, 1.18433707, 1.30799176, 1.2466224 , 1.02999771,\n",
            "       1.10487749, 1.05885047, 1.2603618 , 1.17128463, 1.09594687,\n",
            "       1.10579345, 1.09251202, 1.05930845, 1.10373254, 1.11380811,\n",
            "       1.02953973, 1.51957866, 1.04373712, 1.25166018, 1.1673918 ,\n",
            "       1.21685368, 1.05541562, 1.18021525, 1.10029769, 1.16326998,\n",
            "       1.00526677, 1.09457293, 1.00549576, 1.07716968, 1.08701626,\n",
            "       1.05793451, 1.05449966, 1.07190291, 1.14953057, 1.40531257,\n",
            "       1.12846348, 1.11266316, 1.06778109, 1.13464621, 1.14014197,\n",
            "       1.09022212, 1.75727044, 1.1348752 , 1.09411495, 1.22120449,\n",
            "       1.08197847, 1.10029769, 1.08976414, 1.1209068 , 1.09800779,\n",
            "       1.10052668, 1.02610488, 1.07007099, 1.28028395, 1.0790016 ,\n",
            "       1.37829173, 1.06365926, 1.06388825, 1.04167621, 1.15846119,\n",
            "       1.05289673, 1.07167392, 1.78337531, 1.06869705, 1.31302954,\n",
            "       1.03755439, 1.07304786, 1.08884818, 1.09136707, 1.0487749 ,\n",
            "       1.10350355, 1.0279368 , 1.03366155, 1.10396153, 1.03938631,\n",
            "       1.07098695, 1.19601557, 1.47858942, 1.06091138, 1.0510648 ,\n",
            "       1.30776277, 1.35104191, 1.05724754, 1.05060682, 1.03663842,\n",
            "       1.07968857, 1.03595145, 1.19853446, 1.08541333, 1.03801237,\n",
            "       1.16372796, 1.09205404, 1.30844974, 1.09892375, 1.08037554,\n",
            "       1.00183192, 1.05060682, 1.86764369, 1.09754981, 1.05678956,\n",
            "       1.28990153, 1.0208381 , 1.05999542, 1.05472865, 1.08197847,\n",
            "       1.31669338, 1.07281887, 1.08564232, 1.05472865, 1.01122052,\n",
            "       1.09663384, 1.15937715, 1.04350813, 1.53423403, 1.10579345,\n",
            "       1.07602473, 1.00137394, 1.1417449 , 1.07625372, 1.0767117 ,\n",
            "       1.06205633, 1.11060224, 1.11518205, 1.03640943, 1.0370964 ,\n",
            "       1.10441951, 1.07739867, 1.36730021, 1.08861919, 1.09045111,\n",
            "       1.04488207, 1.05907946, 1.35699565, 1.09480192, 1.09045111,\n",
            "       1.03572246, 1.07029998, 1.27845203, 1.08793222, 1.25051523,\n",
            "       1.1069384 , 1.03389054, 1.09892375, 1.11930387, 1.22578429,\n",
            "       1.18731395, 1.12892146, 1.2905885 , 1.07281887, 1.07029998,\n",
            "       1.46072819, 1.2349439 , 1.1046485 , 1.0581635 , 1.27272727,\n",
            "       1.06182734, 1.48477215, 1.14357683, 1.16487291, 1.26929242,\n",
            "       1.0767117 , 1.03320357, 1.01557133, 1.05266774, 1.09869476,\n",
            "       1.17197161, 1.04831692, 1.03915732, 1.09136707, 1.04236318,\n",
            "       1.14678269, 1.09594687, 1.11128921, 1.06686512, 1.08037554,\n",
            "       1.31531944, 1.15136249, 1.25005725, 1.07831463, 1.04465308,\n",
            "       1.09823678, 1.20861003, 1.069842  , 1.12686054, 1.08312343,\n",
            "       1.15273643, 1.05129379, 1.03824136, 1.68811541, 1.02931074,\n",
            "       1.04007328, 1.15456835, 1.04282116, 1.0558736 , 1.00137394,\n",
            "       1.08907717, 1.0977788 , 1.08152049, 1.08060453, 1.02404397,\n",
            "       1.0373254 , 1.08403939, 1.10533547, 1.12983742, 1.02106709,\n",
            "       1.16784978, 1.11174719, 1.11357912, 1.10854133, 1.75360659,\n",
            "       1.07579574, 1.98671857, 1.04831692, 1.09983971, 1.1813602 ,\n",
            "       1.08999313, 1.20059537, 1.09663384, 1.05472865, 1.09113808,\n",
            "       1.06457522, 1.16670483, 1.05930845, 1.13624914, 1.14014197,\n",
            "       1.09022212, 1.08060453, 1.08106251, 1.20952599, 1.09594687,\n",
            "       1.10327456, 1.04854591, 1.12502862, 1.10945729, 1.09800779,\n",
            "       1.13373025, 1.09846577, 1.12594458, 1.0838104 , 1.17151362,\n",
            "       1.03984429, 1.09022212, 1.05953744, 1.36523929, 1.13144035,\n",
            "       1.01900618, 1.08426838, 1.07487978, 1.19097779, 1.08472636,\n",
            "       1.0767117 , 1.35607969, 1.64048546, 1.16326998, 1.1254866 ,\n",
            "       1.1023586 , 1.01534234, 1.11174719, 1.08655828, 1.15937715,\n",
            "       1.06457522, 1.29722922, 1.0487749 , 1.08747424, 1.06617815,\n",
            "       1.0861003 , 1.12067781, 1.0022899 , 1.06801008, 1.23471491,\n",
            "       1.51362491, 1.35928555, 1.07694069, 2.        , 1.44126403,\n",
            "       1.0861003 , 1.13395924, 1.07762766, 1.03274559, 1.06365926,\n",
            "       1.10327456, 1.1000687 , 1.45019464, 1.04762995, 1.05862148,\n",
            "       1.08701626, 1.0838104 , 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.08106251, 1.2441035 ,\n",
            "       1.11609801, 1.06801008, 1.02518892, 1.13304328, 1.07098695,\n",
            "       1.06686512, 1.05381269, 1.07762766, 1.04076025, 1.01923517,\n",
            "       1.07465079, 1.20036638, 1.04350813, 1.0604534 , 1.04236318,\n",
            "       1.09319899, 1.05381269, 1.12525761, 1.12296771, 1.03068468,\n",
            "       1.15754523, 1.08793222, 1.06869705, 1.01144951, 1.09457293,\n",
            "       1.4000458 , 1.10968628, 1.12686054, 1.20563316, 1.09983971,\n",
            "       1.30799176, 1.2466224 , 1.03801237, 1.11564003, 1.06411724,\n",
            "       1.10487749, 1.05885047, 1.0883902 , 1.2603618 , 1.14220289,\n",
            "       1.16006412, 1.09594687, 1.09251202, 1.51957866, 1.04373712,\n",
            "       1.25166018, 1.1673918 , 1.21685368, 1.10029769, 1.16326998,\n",
            "       1.00526677, 1.09457293, 1.00549576, 1.08701626, 1.08106251,\n",
            "       1.05449966, 1.07190291, 1.14953057, 1.45088161, 1.12846348,\n",
            "       1.11266316, 1.30272498, 1.13464621, 1.14014197, 1.11357912,\n",
            "       1.04030227, 1.75727044, 1.22120449, 1.08197847, 1.10029769,\n",
            "       1.0977788 , 1.03595145, 1.08976414, 1.09800779, 1.02610488,\n",
            "       1.28028395, 1.0790016 , 1.29013052, 1.37829173, 1.06388825,\n",
            "       1.04167621, 1.15846119, 1.10121365, 1.17242959, 1.07739867,\n",
            "       1.08541333, 1.06869705, 1.31302954, 1.29379437, 1.07304786,\n",
            "       1.07098695, 1.08884818, 1.09136707, 1.0487749 , 1.0279368 ,\n",
            "       1.03366155, 1.13144035, 1.10396153, 1.03938631, 1.07098695,\n",
            "       1.19601557, 1.47858942, 1.0510648 , 1.07579574, 1.35104191,\n",
            "       1.05724754, 1.03663842, 1.07968857, 1.03595145, 1.19853446,\n",
            "       1.08541333, 1.03801237, 1.03366155, 1.16372796, 1.09205404,\n",
            "       1.30844974, 1.09892375, 1.08037554, 1.00183192, 1.05060682,\n",
            "       1.09754981, 1.05678956, 1.28990153, 1.0208381 , 1.10716739,\n",
            "       1.09686283, 1.05999542, 1.15800321, 1.08197847, 1.10670941,\n",
            "       1.31669338, 1.07281887, 1.05472865, 1.09663384, 1.15937715,\n",
            "       1.04350813, 1.53423403, 1.07602473, 1.1417449 , 1.07625372,\n",
            "       1.0767117 , 1.06205633, 1.11060224, 1.02060911, 1.10441951,\n",
            "       1.07739867, 1.36730021, 1.09045111, 1.04488207, 1.05907946,\n",
            "       1.35699565, 1.03572246, 1.08793222, 1.25051523, 1.14815663,\n",
            "       1.06778109, 1.1069384 , 1.12846348, 1.03389054, 1.09892375,\n",
            "       1.11930387, 1.07923059, 1.18731395, 1.12892146, 1.07281887,\n",
            "       1.13144035, 1.46072819, 1.07419281, 1.2349439 , 1.11678498,\n",
            "       1.0581635 , 1.27272727, 1.06182734, 1.09274101, 1.14357683,\n",
            "       1.13166934, 1.16487291, 1.26929242, 1.0767117 , 1.03320357,\n",
            "       1.23150905, 1.01557133, 1.05266774, 1.08770323, 1.09869476,\n",
            "       1.17197161, 1.08266545, 1.07831463, 1.04831692, 1.03915732,\n",
            "       1.09136707, 1.14678269, 1.09594687, 1.11128921, 1.06686512,\n",
            "       1.08037554, 1.31531944, 1.53858484, 1.07831463, 1.04465308,\n",
            "       1.14586673, 1.12960843, 1.08312343, 1.01923517, 1.15273643,\n",
            "       1.05129379, 1.03824136, 1.14586673, 1.04007328, 1.09869476,\n",
            "       1.15456835, 1.00137394, 1.17838333, 1.08907717, 1.08770323,\n",
            "       1.0977788 , 1.08152049, 1.08060453, 1.05564461, 1.26402565,\n",
            "       1.02404397, 1.0373254 , 1.07281887, 1.02106709, 1.05885047,\n",
            "       1.15960614, 1.16784978, 1.11174719, 1.11357912, 1.41905198,\n",
            "       1.10602244, 1.07579574, 1.98671857, 1.04831692, 1.09983971,\n",
            "       1.1813602 , 1.51454087, 1.07579574, 1.08999313, 1.20059537,\n",
            "       1.09663384, 1.05472865, 1.93771468, 1.09113808, 1.06457522,\n",
            "       1.07785665, 1.05930845, 1.14014197, 1.08060453, 1.08106251,\n",
            "       1.09594687, 1.10327456, 1.04854591, 1.12502862, 1.10945729,\n",
            "       1.08587131, 1.09800779, 1.11426609, 1.09846577, 1.50583925,\n",
            "       1.12594458, 1.0838104 , 1.08655828, 1.03984429, 1.09022212,\n",
            "       1.36523929, 1.13144035, 1.01900618, 1.07487978, 1.22349439,\n",
            "       1.19097779, 1.08472636, 1.0767117 , 1.35607969, 1.64048546,\n",
            "       1.16326998, 1.1254866 , 1.1023586 , 1.01534234, 1.11174719,\n",
            "       1.08655828, 1.15937715, 1.06457522, 1.02862377, 1.04396611,\n",
            "       1.14838562, 1.0487749 , 1.0861003 , 1.12067781, 1.0022899 ,\n",
            "       1.12594458, 1.06801008, 1.23471491, 1.51362491, 1.35928555,\n",
            "       1.07694069, 2.        , 1.44126403, 1.07762766, 1.12823449,\n",
            "       1.11083123, 1.03274559, 1.06365926, 1.10327456, 1.10831234,\n",
            "       1.1000687 , 1.45019464, 1.04762995, 1.05862148, 1.07373483,\n",
            "       1.08701626, 1.0838104 , 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.10877032, 1.09342798, 1.08106251, 1.2441035 , 1.11609801,\n",
            "       1.06801008, 1.02518892, 1.13304328, 1.07098695, 1.06411724,\n",
            "       1.07762766, 1.04076025, 1.07465079, 1.22647126, 1.0604534 ,\n",
            "       1.08770323, 1.09319899, 1.12296771, 1.03068468, 1.15754523,\n",
            "       1.06869705, 1.01144951, 1.10968628, 1.12686054, 1.20563316,\n",
            "       1.18433707, 1.09983971, 1.2466224 , 1.03801237, 1.11564003,\n",
            "       1.02999771, 1.06411724, 1.10487749, 1.05885047, 1.0883902 ,\n",
            "       1.14220289, 1.16006412, 1.17128463, 1.09594687, 1.10579345,\n",
            "       1.09251202, 1.05930845, 1.10373254, 1.11380811, 1.02953973,\n",
            "       1.04373712, 1.21685368, 1.05541562, 1.18021525, 1.10029769,\n",
            "       1.16326998, 1.00526677, 1.09457293, 1.07716968, 1.05793451,\n",
            "       1.08106251, 1.05449966, 1.07190291, 1.14953057, 1.40531257,\n",
            "       1.45088161, 1.12846348, 1.11266316, 1.30272498, 1.06778109,\n",
            "       1.13464621, 1.14014197, 1.09022212, 1.11357912, 1.04030227,\n",
            "       1.1348752 , 1.09411495, 1.22120449, 1.0977788 , 1.03595145,\n",
            "       1.08976414, 1.1209068 , 1.09800779, 1.10052668, 1.07007099,\n",
            "       1.28028395, 1.29013052, 1.37829173, 1.06365926, 1.04167621,\n",
            "       1.15846119, 1.10121365, 1.05289673, 1.17242959, 1.07167392,\n",
            "       1.07739867, 1.78337531, 1.08541333, 1.06869705, 1.31302954,\n",
            "       1.29379437, 1.03755439, 1.07304786, 1.07098695, 1.08884818,\n",
            "       1.09136707, 1.0487749 , 1.10350355, 1.0279368 , 1.03366155,\n",
            "       1.13144035, 1.10396153, 1.19601557, 1.47858942, 1.06091138,\n",
            "       1.0510648 , 1.07579574, 1.30776277, 1.05724754, 1.05060682,\n",
            "       1.03663842, 1.07968857, 1.03595145, 1.19853446, 1.08541333,\n",
            "       1.03366155, 1.09205404, 1.08037554, 1.00183192, 1.05060682,\n",
            "       1.86764369, 1.09754981, 1.05678956, 1.10716739, 1.09686283,\n",
            "       1.05999542, 1.05472865, 1.15800321, 1.08197847, 1.10670941,\n",
            "       1.31669338, 1.08564232, 1.01122052, 1.15937715, 1.04350813,\n",
            "       1.53423403, 1.10579345, 1.07602473, 1.00137394, 1.1417449 ,\n",
            "       1.06205633, 1.11518205, 1.03640943, 1.0370964 , 1.02060911,\n",
            "       1.10441951, 1.07739867, 1.36730021, 1.08861919, 1.09045111,\n",
            "       1.05907946, 1.35699565, 1.09480192, 1.09045111, 1.03572246,\n",
            "       1.07029998, 1.27845203, 1.08793222, 1.25051523, 1.14815663,\n",
            "       1.06778109, 1.12846348, 1.03389054, 1.11930387, 1.07923059,\n",
            "       1.22578429, 1.18731395, 1.2905885 , 1.07281887, 1.07029998,\n",
            "       1.13144035, 1.46072819, 1.07419281, 1.2349439 , 1.1046485 ,\n",
            "       1.11678498, 1.0581635 , 1.27272727, 1.48477215, 1.09274101,\n",
            "       1.14357683, 1.13166934, 1.26929242, 1.0767117 , 1.03320357,\n",
            "       1.23150905, 1.01557133, 1.08770323, 1.09869476, 1.17197161,\n",
            "       1.08266545, 1.07831463, 1.03915732, 1.09136707, 1.04236318,\n",
            "       1.14678269, 1.09594687, 1.11128921, 1.08037554, 1.31531944,\n",
            "       1.53858484, 1.15136249, 1.25005725, 1.07831463, 1.04465308,\n",
            "       1.09823678, 1.14586673, 1.20861003, 1.069842  , 1.12960843,\n",
            "       1.12686054, 1.01923517, 1.15273643, 1.03824136, 1.68811541,\n",
            "       1.14586673, 1.02931074, 1.04007328, 1.09869476, 1.04282116,\n",
            "       1.0558736 , 1.00137394, 1.17838333, 1.08907717, 1.08770323,\n",
            "       1.0977788 , 1.05564461, 1.26402565, 1.08403939, 1.10533547,\n",
            "       1.12983742, 1.07281887, 1.05885047, 1.15960614, 1.16784978,\n",
            "       1.11174719, 1.11357912, 1.41905198, 1.10602244, 1.10854133,\n",
            "       1.75360659, 1.98671857, 1.04831692, 1.09983971, 1.1813602 ,\n",
            "       1.51454087, 1.07579574, 1.08999313, 1.20059537, 1.05472865,\n",
            "       1.93771468, 1.09113808, 1.06457522, 1.16670483, 1.07785665,\n",
            "       1.05930845, 1.13624914, 1.09022212, 1.08060453, 1.08106251,\n",
            "       1.20952599, 1.09594687, 1.10327456, 1.04854591, 1.10945729,\n",
            "       1.08587131, 1.13373025, 1.11426609, 1.09846577, 1.50583925,\n",
            "       1.12594458, 1.17151362, 1.08655828, 1.09022212, 1.05953744,\n",
            "       1.13144035, 1.08426838, 1.22349439, 1.08472636, 1.0767117 ,\n",
            "       1.16326998, 1.1254866 , 1.01534234, 1.08655828, 1.15937715,\n",
            "       1.02862377, 1.29722922, 1.04396611, 1.14838562, 1.0487749 ,\n",
            "       1.08747424, 1.06617815, 1.0861003 , 1.12067781, 1.0022899 ,\n",
            "       1.12594458, 1.06801008, 1.23471491, 1.51362491, 1.35928555,\n",
            "       1.07694069, 2.        , 1.0861003 , 1.13395924, 1.12823449,\n",
            "       1.11083123, 1.03274559, 1.10831234, 1.45019464, 1.04762995,\n",
            "       1.07373483, 1.08701626, 1.0838104 , 1.0396153 , 1.06663613]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.11609801, 1.06801008, 1.02518892, 1.07098695,\n",
            "       1.06686512, 1.06411724, 1.05381269, 1.07762766, 1.01923517,\n",
            "       1.07465079, 1.20036638, 1.22647126, 1.04350813, 1.04236318,\n",
            "       1.08770323, 1.05381269, 1.12525761, 1.12296771, 1.03068468,\n",
            "       1.08793222, 1.06869705, 1.09457293, 1.4000458 , 1.12686054,\n",
            "       1.20563316, 1.18433707, 1.09983971, 1.30799176, 1.03801237,\n",
            "       1.11564003, 1.02999771, 1.06411724, 1.0883902 , 1.2603618 ,\n",
            "       1.14220289, 1.16006412, 1.17128463, 1.09594687, 1.10579345,\n",
            "       1.09251202, 1.05930845, 1.10373254, 1.11380811, 1.02953973,\n",
            "       1.51957866, 1.25166018, 1.1673918 , 1.05541562, 1.18021525,\n",
            "       1.10029769, 1.09457293, 1.00549576, 1.07716968, 1.08701626,\n",
            "       1.05793451, 1.08106251, 1.05449966, 1.14953057, 1.40531257,\n",
            "       1.45088161, 1.12846348, 1.11266316, 1.30272498, 1.06778109,\n",
            "       1.09022212, 1.11357912, 1.04030227, 1.75727044, 1.1348752 ,\n",
            "       1.09411495, 1.08197847, 1.10029769, 1.0977788 , 1.03595145,\n",
            "       1.08976414, 1.1209068 , 1.10052668, 1.02610488, 1.07007099,\n",
            "       1.0790016 , 1.29013052, 1.06365926, 1.06388825, 1.15846119,\n",
            "       1.10121365, 1.05289673, 1.17242959, 1.07167392, 1.07739867,\n",
            "       1.78337531, 1.08541333, 1.06869705, 1.29379437, 1.03755439,\n",
            "       1.07098695, 1.09136707, 1.10350355, 1.0279368 , 1.13144035,\n",
            "       1.10396153, 1.03938631, 1.07098695, 1.47858942, 1.06091138,\n",
            "       1.0510648 , 1.07579574, 1.30776277, 1.35104191, 1.05060682,\n",
            "       1.03663842, 1.08541333, 1.03801237, 1.03366155, 1.16372796,\n",
            "       1.09205404, 1.30844974, 1.09892375, 1.00183192, 1.05060682,\n",
            "       1.86764369, 1.09754981, 1.05678956, 1.28990153, 1.0208381 ,\n",
            "       1.10716739, 1.09686283, 1.05999542, 1.05472865, 1.15800321,\n",
            "       1.08197847, 1.10670941, 1.31669338, 1.07281887, 1.08564232,\n",
            "       1.05472865, 1.01122052, 1.09663384, 1.04350813, 1.53423403,\n",
            "       1.10579345, 1.00137394, 1.1417449 , 1.07625372, 1.0767117 ,\n",
            "       1.11060224, 1.11518205, 1.03640943, 1.0370964 , 1.02060911,\n",
            "       1.07739867, 1.08861919, 1.09045111, 1.04488207, 1.05907946,\n",
            "       1.09480192, 1.09045111, 1.07029998, 1.27845203, 1.08793222,\n",
            "       1.14815663, 1.06778109, 1.1069384 , 1.12846348, 1.09892375,\n",
            "       1.11930387, 1.07923059, 1.22578429, 1.12892146, 1.2905885 ,\n",
            "       1.07029998, 1.13144035, 1.07419281, 1.2349439 , 1.1046485 ,\n",
            "       1.11678498, 1.27272727, 1.06182734, 1.48477215, 1.09274101,\n",
            "       1.14357683, 1.13166934, 1.16487291, 1.26929242, 1.0767117 ,\n",
            "       1.23150905, 1.05266774, 1.08770323, 1.09869476, 1.08266545,\n",
            "       1.07831463, 1.04831692, 1.03915732, 1.09136707, 1.04236318,\n",
            "       1.14678269, 1.06686512, 1.53858484, 1.15136249, 1.25005725,\n",
            "       1.07831463, 1.09823678, 1.14586673, 1.20861003, 1.069842  ,\n",
            "       1.12960843, 1.12686054, 1.08312343, 1.01923517, 1.15273643,\n",
            "       1.05129379, 1.68811541, 1.14586673, 1.02931074, 1.04007328,\n",
            "       1.09869476, 1.15456835, 1.04282116, 1.0558736 , 1.00137394,\n",
            "       1.17838333, 1.08907717, 1.08770323, 1.0977788 , 1.08152049,\n",
            "       1.08060453, 1.05564461, 1.26402565, 1.02404397, 1.0373254 ,\n",
            "       1.08403939, 1.10533547, 1.12983742, 1.07281887, 1.02106709,\n",
            "       1.05885047, 1.15960614, 1.11357912, 1.41905198, 1.10602244,\n",
            "       1.10854133, 1.75360659, 1.07579574, 1.98671857, 1.1813602 ,\n",
            "       1.51454087, 1.07579574, 1.08999313, 1.20059537, 1.09663384,\n",
            "       1.05472865, 1.93771468, 1.16670483, 1.07785665, 1.05930845,\n",
            "       1.13624914, 1.14014197, 1.09022212, 1.08060453, 1.20952599,\n",
            "       1.09594687, 1.10327456, 1.12502862, 1.08587131, 1.09800779,\n",
            "       1.13373025, 1.11426609, 1.09846577, 1.50583925, 1.0838104 ,\n",
            "       1.17151362, 1.08655828, 1.03984429, 1.09022212, 1.05953744,\n",
            "       1.36523929, 1.01900618, 1.08426838, 1.07487978, 1.22349439,\n",
            "       1.19097779, 1.08472636, 1.0767117 , 1.35607969, 1.64048546,\n",
            "       1.16326998, 1.1023586 , 1.11174719, 1.15937715, 1.06457522,\n",
            "       1.02862377, 1.29722922, 1.04396611, 1.14838562, 1.0487749 ,\n",
            "       1.08747424, 1.06617815, 1.12067781, 1.12594458, 1.06801008,\n",
            "       1.51362491, 1.07694069, 2.        , 1.44126403, 1.0861003 ,\n",
            "       1.13395924, 1.07762766, 1.12823449, 1.11083123, 1.06365926,\n",
            "       1.10327456, 1.10831234, 1.1000687 , 1.45019464, 1.04762995,\n",
            "       1.05862148, 1.07373483, 1.0838104 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.10877032, 1.09342798, 1.08106251, 1.11609801, 1.06801008,\n",
            "       1.02518892, 1.13304328, 1.07098695, 1.06686512, 1.06411724,\n",
            "       1.05381269, 1.07762766, 1.01923517, 1.20036638, 1.22647126,\n",
            "       1.04350813, 1.04236318, 1.08770323, 1.05381269, 1.12525761,\n",
            "       1.03068468, 1.15754523, 1.08793222, 1.06869705, 1.01144951,\n",
            "       1.09457293, 1.10968628, 1.18433707, 1.09983971, 1.30799176,\n",
            "       1.2466224 , 1.03801237, 1.11564003, 1.02999771, 1.06411724,\n",
            "       1.10487749, 1.05885047, 1.0883902 , 1.2603618 , 1.14220289,\n",
            "       1.16006412, 1.17128463, 1.09594687, 1.10579345, 1.09251202,\n",
            "       1.05930845, 1.10373254, 1.11380811, 1.02953973, 1.04373712,\n",
            "       1.25166018, 1.1673918 , 1.21685368, 1.05541562, 1.18021525,\n",
            "       1.10029769, 1.16326998, 1.00526677, 1.00549576, 1.07716968,\n",
            "       1.08701626, 1.05793451, 1.05449966, 1.07190291, 1.45088161,\n",
            "       1.12846348, 1.11266316, 1.30272498, 1.06778109, 1.13464621,\n",
            "       1.14014197, 1.11357912, 1.04030227, 1.1348752 , 1.09411495,\n",
            "       1.22120449, 1.08197847, 1.10029769, 1.0977788 , 1.03595145,\n",
            "       1.1209068 , 1.09800779, 1.10052668, 1.02610488, 1.07007099,\n",
            "       1.28028395, 1.0790016 , 1.37829173, 1.06365926, 1.06388825,\n",
            "       1.04167621, 1.15846119, 1.10121365, 1.05289673, 1.17242959,\n",
            "       1.07739867, 1.78337531, 1.06869705, 1.31302954, 1.29379437,\n",
            "       1.03755439, 1.07098695, 1.08884818, 1.09136707, 1.0487749 ,\n",
            "       1.10350355, 1.0279368 , 1.03366155, 1.13144035, 1.03938631,\n",
            "       1.07098695, 1.19601557, 1.47858942, 1.06091138, 1.07579574,\n",
            "       1.30776277, 1.05724754, 1.05060682, 1.03663842, 1.07968857,\n",
            "       1.03595145, 1.19853446, 1.03366155, 1.16372796, 1.09205404,\n",
            "       1.30844974, 1.09892375, 1.86764369, 1.09754981, 1.05678956,\n",
            "       1.0208381 , 1.05999542, 1.05472865, 1.08197847, 1.31669338,\n",
            "       1.07281887, 1.05472865, 1.01122052, 1.09663384, 1.04350813,\n",
            "       1.53423403, 1.10579345, 1.07602473, 1.1417449 , 1.07625372,\n",
            "       1.0767117 , 1.06205633, 1.11518205, 1.03640943, 1.0370964 ,\n",
            "       1.02060911, 1.10441951, 1.07739867, 1.36730021, 1.08861919,\n",
            "       1.09045111, 1.04488207, 1.35699565, 1.09480192, 1.03572246,\n",
            "       1.07029998, 1.27845203, 1.14815663, 1.06778109, 1.1069384 ,\n",
            "       1.12846348, 1.03389054, 1.09892375, 1.11930387, 1.07923059,\n",
            "       1.22578429, 1.18731395, 1.12892146, 1.2905885 , 1.07281887,\n",
            "       1.07029998, 1.13144035, 1.46072819, 1.07419281, 1.2349439 ,\n",
            "       1.1046485 , 1.11678498, 1.0581635 , 1.27272727, 1.06182734,\n",
            "       1.48477215, 1.09274101, 1.13166934, 1.16487291, 1.26929242,\n",
            "       1.0767117 , 1.03320357, 1.23150905, 1.01557133, 1.09869476,\n",
            "       1.17197161, 1.08266545, 1.07831463, 1.04831692, 1.03915732,\n",
            "       1.04236318, 1.14678269, 1.09594687, 1.11128921, 1.08037554,\n",
            "       1.53858484, 1.15136249, 1.25005725, 1.04465308, 1.09823678,\n",
            "       1.14586673, 1.20861003, 1.12960843, 1.12686054, 1.08312343,\n",
            "       1.15273643, 1.05129379, 1.03824136, 1.68811541, 1.14586673,\n",
            "       1.02931074, 1.15456835, 1.0558736 , 1.00137394, 1.17838333,\n",
            "       1.08907717, 1.08770323, 1.0977788 , 1.08152049, 1.08060453,\n",
            "       1.05564461, 1.02404397, 1.0373254 , 1.08403939, 1.10533547,\n",
            "       1.12983742, 1.07281887, 1.05885047, 1.15960614, 1.16784978,\n",
            "       1.11174719, 1.10602244, 1.10854133, 1.75360659, 1.07579574,\n",
            "       1.98671857, 1.09983971, 1.1813602 , 1.51454087, 1.07579574,\n",
            "       1.08999313, 1.05472865, 1.93771468, 1.09113808, 1.06457522,\n",
            "       1.07785665, 1.05930845, 1.13624914, 1.09022212, 1.08060453,\n",
            "       1.08106251, 1.09594687, 1.04854591, 1.12502862, 1.10945729,\n",
            "       1.08587131, 1.09800779, 1.11426609, 1.09846577, 1.12594458,\n",
            "       1.17151362, 1.08655828, 1.03984429, 1.09022212, 1.05953744,\n",
            "       1.36523929, 1.13144035, 1.01900618, 1.08426838, 1.07487978,\n",
            "       1.22349439, 1.08472636, 1.0767117 , 1.35607969, 1.1023586 ,\n",
            "       1.01534234, 1.11174719, 1.08655828, 1.15937715, 1.06457522,\n",
            "       1.02862377, 1.29722922, 1.04396611, 1.14838562, 1.0487749 ,\n",
            "       1.06617815, 1.0861003 , 1.12067781, 1.0022899 , 1.12594458,\n",
            "       1.06801008, 1.51362491, 1.35928555, 1.07694069, 2.        ,\n",
            "       1.44126403, 1.07762766, 1.12823449, 1.03274559, 1.06365926,\n",
            "       1.10327456, 1.10831234, 1.1000687 , 1.45019464, 1.04762995,\n",
            "       1.05862148, 1.07373483, 1.08701626, 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.08106251, 1.2441035 ,\n",
            "       1.11609801, 1.06801008, 1.02518892, 1.13304328, 1.07098695,\n",
            "       1.06686512, 1.06411724, 1.05381269, 1.07762766, 1.04076025,\n",
            "       1.01923517, 1.07465079, 1.20036638, 1.22647126, 1.0604534 ,\n",
            "       1.04236318, 1.08770323, 1.09319899, 1.05381269, 1.12525761,\n",
            "       1.12296771, 1.03068468, 1.08793222, 1.06869705, 1.09457293,\n",
            "       1.4000458 , 1.12686054, 1.20563316, 1.18433707, 1.30799176,\n",
            "       1.2466224 , 1.03801237, 1.11564003, 1.02999771, 1.10487749,\n",
            "       1.05885047, 1.0883902 , 1.2603618 , 1.16006412, 1.17128463,\n",
            "       1.09594687, 1.10579345, 1.09251202, 1.05930845, 1.10373254,\n",
            "       1.11380811, 1.02953973, 1.51957866, 1.04373712, 1.25166018,\n",
            "       1.1673918 , 1.21685368, 1.18021525, 1.10029769, 1.00526677,\n",
            "       1.09457293, 1.00549576, 1.07716968, 1.08701626, 1.08106251,\n",
            "       1.05449966, 1.07190291, 1.14953057, 1.40531257, 1.45088161,\n",
            "       1.11266316, 1.30272498, 1.06778109, 1.14014197, 1.09022212,\n",
            "       1.11357912, 1.75727044, 1.1348752 , 1.09411495, 1.22120449,\n",
            "       1.08197847, 1.10029769, 1.0977788 , 1.08976414, 1.1209068 ,\n",
            "       1.10052668, 1.02610488, 1.07007099, 1.29013052, 1.06388825,\n",
            "       1.15846119, 1.10121365, 1.17242959, 1.07167392, 1.07739867,\n",
            "       1.78337531, 1.08541333, 1.29379437, 1.07304786, 1.07098695,\n",
            "       1.09136707, 1.10350355, 1.10396153, 1.03938631, 1.07098695,\n",
            "       1.19601557, 1.47858942, 1.06091138, 1.0510648 , 1.30776277,\n",
            "       1.35104191, 1.05724754, 1.05060682, 1.03663842, 1.19853446,\n",
            "       1.08541333, 1.03801237, 1.03366155, 1.16372796, 1.09205404,\n",
            "       1.30844974, 1.09892375, 1.08037554, 1.00183192, 1.05060682,\n",
            "       1.86764369, 1.09754981, 1.05678956, 1.28990153, 1.0208381 ,\n",
            "       1.10716739, 1.09686283, 1.05999542, 1.05472865, 1.15800321,\n",
            "       1.10670941, 1.31669338, 1.07281887, 1.08564232, 1.05472865,\n",
            "       1.01122052, 1.09663384, 1.15937715, 1.10579345, 1.00137394,\n",
            "       1.1417449 , 1.07625372, 1.06205633, 1.11060224, 1.11518205,\n",
            "       1.0370964 , 1.02060911, 1.10441951, 1.07739867, 1.36730021,\n",
            "       1.08861919, 1.09045111, 1.05907946, 1.09480192, 1.09045111,\n",
            "       1.03572246, 1.08793222, 1.25051523, 1.14815663, 1.06778109,\n",
            "       1.1069384 , 1.12846348, 1.03389054, 1.09892375, 1.11930387,\n",
            "       1.18731395, 1.2905885 , 1.07281887, 1.07029998, 1.13144035,\n",
            "       1.46072819, 1.2349439 , 1.1046485 , 1.11678498, 1.0581635 ,\n",
            "       1.27272727, 1.48477215, 1.09274101, 1.14357683, 1.13166934,\n",
            "       1.16487291, 1.26929242, 1.0767117 , 1.23150905, 1.01557133,\n",
            "       1.05266774, 1.08770323, 1.17197161, 1.08266545, 1.04831692,\n",
            "       1.03915732, 1.09136707, 1.04236318, 1.14678269, 1.09594687,\n",
            "       1.11128921, 1.06686512, 1.31531944, 1.07831463, 1.04465308,\n",
            "       1.09823678, 1.14586673, 1.069842  , 1.12960843, 1.08312343,\n",
            "       1.01923517, 1.15273643, 1.05129379, 1.03824136, 1.68811541,\n",
            "       1.02931074, 1.04007328, 1.09869476, 1.15456835, 1.04282116,\n",
            "       1.0558736 , 1.00137394, 1.17838333, 1.08907717, 1.08770323,\n",
            "       1.0977788 , 1.08152049, 1.05564461, 1.26402565, 1.02404397,\n",
            "       1.0373254 , 1.10533547, 1.12983742, 1.07281887, 1.02106709,\n",
            "       1.05885047, 1.15960614, 1.16784978, 1.11174719, 1.11357912,\n",
            "       1.41905198, 1.10602244, 1.10854133, 1.75360659, 1.04831692,\n",
            "       1.09983971, 1.51454087, 1.07579574, 1.08999313, 1.20059537,\n",
            "       1.09663384, 1.05472865, 1.93771468, 1.06457522, 1.16670483,\n",
            "       1.07785665, 1.14014197, 1.08060453, 1.08106251, 1.20952599,\n",
            "       1.09594687, 1.10327456, 1.04854591, 1.09800779, 1.13373025,\n",
            "       1.11426609, 1.09846577, 1.50583925, 1.12594458, 1.0838104 ,\n",
            "       1.17151362, 1.08655828, 1.03984429, 1.09022212, 1.05953744,\n",
            "       1.36523929, 1.13144035, 1.01900618, 1.07487978, 1.22349439,\n",
            "       1.19097779, 1.0767117 , 1.35607969, 1.64048546, 1.16326998,\n",
            "       1.1254866 , 1.1023586 , 1.11174719, 1.15937715, 1.29722922,\n",
            "       1.04396611, 1.14838562, 1.0487749 , 1.08747424, 1.06617815,\n",
            "       1.12067781, 1.12594458, 1.06801008, 1.23471491, 1.51362491,\n",
            "       1.35928555, 1.07694069, 2.        , 1.44126403, 1.0861003 ,\n",
            "       1.13395924, 1.07762766, 1.11083123, 1.03274559, 1.06365926,\n",
            "       1.10327456, 1.45019464, 1.04762995, 1.05862148, 1.07373483,\n",
            "       1.08701626, 1.0838104 , 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.08106251, 1.2441035 ,\n",
            "       1.11609801, 1.02518892, 1.13304328, 1.06686512, 1.04076025,\n",
            "       1.07465079, 1.20036638, 1.22647126, 1.04350813, 1.0604534 ,\n",
            "       1.08770323, 1.09319899, 1.12525761, 1.12296771, 1.15754523,\n",
            "       1.06869705, 1.01144951, 1.09457293, 1.4000458 , 1.10968628,\n",
            "       1.12686054, 1.20563316, 1.09983971, 1.30799176, 1.2466224 ,\n",
            "       1.03801237, 1.02999771, 1.06411724, 1.05885047, 1.0883902 ,\n",
            "       1.14220289, 1.17128463, 1.10579345, 1.09251202, 1.05930845,\n",
            "       1.10373254, 1.11380811, 1.02953973, 1.51957866, 1.04373712,\n",
            "       1.25166018, 1.21685368, 1.05541562, 1.10029769, 1.16326998,\n",
            "       1.00526677, 1.09457293, 1.00549576, 1.07716968, 1.08701626,\n",
            "       1.05793451, 1.08106251, 1.05449966, 1.07190291, 1.14953057,\n",
            "       1.40531257, 1.45088161, 1.12846348, 1.11266316, 1.30272498,\n",
            "       1.06778109, 1.13464621, 1.14014197, 1.09022212, 1.04030227,\n",
            "       1.75727044, 1.1348752 , 1.22120449, 1.08197847, 1.10029769,\n",
            "       1.0977788 , 1.03595145, 1.08976414, 1.1209068 , 1.09800779,\n",
            "       1.02610488, 1.28028395, 1.0790016 , 1.29013052, 1.37829173,\n",
            "       1.06365926, 1.06388825, 1.04167621, 1.15846119, 1.10121365,\n",
            "       1.05289673, 1.17242959, 1.07167392, 1.08541333, 1.06869705,\n",
            "       1.31302954, 1.29379437, 1.03755439, 1.07304786, 1.07098695,\n",
            "       1.08884818, 1.09136707, 1.0487749 , 1.0279368 , 1.03366155,\n",
            "       1.13144035, 1.10396153, 1.07098695, 1.19601557, 1.0510648 ,\n",
            "       1.07579574, 1.30776277, 1.35104191, 1.05724754, 1.03663842,\n",
            "       1.07968857, 1.03595145, 1.19853446, 1.08541333, 1.03801237,\n",
            "       1.03366155, 1.09892375, 1.08037554, 1.00183192, 1.05060682,\n",
            "       1.86764369, 1.09754981, 1.05678956, 1.28990153, 1.10716739,\n",
            "       1.09686283, 1.05999542, 1.05472865, 1.15800321, 1.08197847,\n",
            "       1.10670941, 1.31669338, 1.07281887, 1.08564232, 1.05472865,\n",
            "       1.09663384, 1.15937715, 1.04350813, 1.53423403, 1.10579345,\n",
            "       1.07602473, 1.00137394, 1.1417449 , 1.07625372, 1.0767117 ,\n",
            "       1.06205633, 1.11060224, 1.11518205, 1.03640943, 1.10441951,\n",
            "       1.07739867, 1.08861919, 1.04488207, 1.05907946, 1.35699565,\n",
            "       1.09480192, 1.09045111, 1.03572246, 1.07029998, 1.27845203,\n",
            "       1.08793222, 1.25051523, 1.14815663, 1.06778109, 1.12846348,\n",
            "       1.11930387, 1.07923059, 1.22578429, 1.12892146, 1.2905885 ,\n",
            "       1.07281887, 1.13144035, 1.46072819, 1.07419281, 1.1046485 ,\n",
            "       1.06182734, 1.48477215, 1.09274101, 1.14357683, 1.13166934,\n",
            "       1.16487291, 1.26929242, 1.0767117 , 1.03320357, 1.23150905,\n",
            "       1.05266774, 1.08770323, 1.09869476, 1.08266545, 1.07831463,\n",
            "       1.04831692, 1.03915732, 1.09136707, 1.04236318, 1.14678269,\n",
            "       1.09594687, 1.06686512, 1.08037554, 1.31531944, 1.53858484,\n",
            "       1.15136249, 1.25005725, 1.07831463, 1.20861003, 1.069842  ,\n",
            "       1.12960843, 1.12686054, 1.08312343, 1.01923517, 1.05129379,\n",
            "       1.03824136, 1.14586673, 1.02931074, 1.04007328, 1.09869476,\n",
            "       1.15456835, 1.04282116, 1.00137394, 1.17838333, 1.08907717,\n",
            "       1.0977788 , 1.08152049, 1.08060453, 1.05564461, 1.26402565,\n",
            "       1.02404397, 1.0373254 , 1.08403939, 1.12983742, 1.07281887,\n",
            "       1.02106709, 1.05885047, 1.11174719, 1.11357912, 1.41905198,\n",
            "       1.10602244, 1.10854133, 1.75360659, 1.07579574, 1.98671857,\n",
            "       1.04831692, 1.1813602 , 1.51454087, 1.07579574, 1.20059537,\n",
            "       1.09663384, 1.05472865, 1.93771468, 1.09113808, 1.16670483,\n",
            "       1.05930845, 1.13624914, 1.14014197, 1.09022212, 1.08060453,\n",
            "       1.08106251, 1.20952599, 1.10327456, 1.04854591, 1.12502862,\n",
            "       1.10945729, 1.08587131, 1.09800779, 1.13373025, 1.09846577,\n",
            "       1.50583925, 1.0838104 , 1.17151362, 1.08655828, 1.03984429,\n",
            "       1.09022212, 1.36523929, 1.08426838, 1.19097779, 1.08472636,\n",
            "       1.0767117 , 1.35607969, 1.64048546, 1.16326998, 1.1254866 ,\n",
            "       1.1023586 , 1.01534234, 1.11174719, 1.08655828, 1.15937715,\n",
            "       1.06457522, 1.02862377, 1.04396611, 1.08747424, 1.06617815,\n",
            "       1.0861003 , 1.12067781, 1.0022899 , 1.12594458, 1.06801008,\n",
            "       1.23471491, 1.51362491, 1.35928555, 2.        , 1.0861003 ,\n",
            "       1.13395924, 1.07762766, 1.12823449, 1.11083123, 1.06365926,\n",
            "       1.10327456, 1.10831234, 1.1000687 , 1.45019464, 1.07373483,\n",
            "       1.08701626, 1.0838104 , 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.08106251, 1.2441035 , 1.06801008,\n",
            "       1.02518892, 1.13304328, 1.07098695, 1.06411724, 1.05381269,\n",
            "       1.07762766, 1.04076025, 1.01923517, 1.07465079, 1.22647126,\n",
            "       1.04350813, 1.0604534 , 1.04236318, 1.08770323, 1.09319899,\n",
            "       1.05381269, 1.12296771, 1.03068468, 1.15754523, 1.08793222,\n",
            "       1.01144951, 1.09457293, 1.4000458 , 1.10968628, 1.12686054,\n",
            "       1.20563316, 1.18433707, 1.09983971, 1.30799176, 1.11564003,\n",
            "       1.06411724, 1.10487749, 1.05885047, 1.0883902 , 1.2603618 ,\n",
            "       1.14220289, 1.16006412, 1.09594687, 1.10373254, 1.11380811,\n",
            "       1.02953973, 1.51957866, 1.04373712, 1.25166018, 1.1673918 ,\n",
            "       1.21685368, 1.05541562, 1.18021525, 1.10029769, 1.16326998,\n",
            "       1.09457293, 1.00549576, 1.05793451, 1.08106251, 1.05449966,\n",
            "       1.07190291, 1.14953057, 1.40531257, 1.12846348, 1.11266316,\n",
            "       1.13464621, 1.09022212, 1.11357912, 1.04030227, 1.75727044,\n",
            "       1.09411495, 1.08197847, 1.10029769, 1.03595145, 1.08976414,\n",
            "       1.09800779, 1.10052668, 1.02610488, 1.07007099, 1.28028395,\n",
            "       1.0790016 , 1.29013052, 1.37829173, 1.06365926, 1.04167621,\n",
            "       1.15846119, 1.10121365, 1.05289673, 1.07167392, 1.07739867,\n",
            "       1.78337531, 1.08541333, 1.06869705, 1.31302954, 1.29379437,\n",
            "       1.03755439, 1.07304786, 1.07098695, 1.08884818, 1.09136707,\n",
            "       1.0487749 , 1.10350355, 1.0279368 , 1.03366155, 1.13144035,\n",
            "       1.10396153, 1.03938631, 1.19601557, 1.47858942, 1.06091138,\n",
            "       1.0510648 , 1.07579574, 1.30776277, 1.35104191, 1.05060682,\n",
            "       1.03663842, 1.07968857, 1.03595145, 1.19853446, 1.08541333,\n",
            "       1.03801237, 1.03366155, 1.16372796, 1.09205404, 1.30844974,\n",
            "       1.09892375, 1.08037554, 1.00183192, 1.05060682, 1.86764369,\n",
            "       1.09754981, 1.28990153, 1.0208381 , 1.10716739, 1.09686283,\n",
            "       1.05999542, 1.05472865, 1.15800321, 1.08197847, 1.10670941,\n",
            "       1.31669338, 1.07281887, 1.08564232, 1.01122052, 1.09663384,\n",
            "       1.15937715, 1.04350813, 1.53423403, 1.10579345, 1.07602473,\n",
            "       1.00137394, 1.07625372, 1.0767117 , 1.11060224, 1.03640943,\n",
            "       1.0370964 , 1.02060911, 1.36730021, 1.08861919, 1.09045111,\n",
            "       1.04488207, 1.05907946, 1.35699565, 1.09045111, 1.03572246,\n",
            "       1.07029998, 1.27845203, 1.08793222, 1.25051523, 1.14815663,\n",
            "       1.06778109, 1.1069384 , 1.12846348, 1.03389054, 1.09892375,\n",
            "       1.11930387, 1.07923059, 1.22578429, 1.18731395, 1.12892146,\n",
            "       1.07281887, 1.07029998, 1.46072819, 1.07419281, 1.2349439 ,\n",
            "       1.1046485 , 1.11678498, 1.0581635 , 1.27272727, 1.06182734,\n",
            "       1.48477215, 1.14357683, 1.16487291, 1.26929242, 1.0767117 ,\n",
            "       1.03320357, 1.01557133, 1.05266774, 1.08770323, 1.09869476,\n",
            "       1.17197161, 1.07831463, 1.03915732, 1.09136707, 1.14678269,\n",
            "       1.11128921, 1.06686512, 1.08037554, 1.31531944, 1.53858484,\n",
            "       1.15136249, 1.25005725, 1.07831463, 1.04465308, 1.09823678,\n",
            "       1.14586673, 1.20861003, 1.069842  , 1.12686054, 1.01923517,\n",
            "       1.15273643, 1.68811541, 1.14586673, 1.04007328, 1.09869476,\n",
            "       1.15456835, 1.04282116, 1.0558736 , 1.08907717, 1.08770323,\n",
            "       1.0977788 , 1.08152049, 1.08060453, 1.26402565, 1.08403939,\n",
            "       1.10533547, 1.12983742, 1.02106709, 1.15960614, 1.16784978,\n",
            "       1.11174719, 1.11357912, 1.41905198, 1.10602244, 1.07579574,\n",
            "       1.98671857, 1.04831692, 1.09983971, 1.1813602 , 1.08999313,\n",
            "       1.20059537, 1.09663384, 1.09113808, 1.06457522, 1.16670483,\n",
            "       1.07785665, 1.05930845, 1.13624914, 1.14014197, 1.09022212,\n",
            "       1.08106251, 1.20952599, 1.09594687, 1.10327456, 1.12502862,\n",
            "       1.10945729, 1.08587131, 1.13373025, 1.11426609, 1.09846577,\n",
            "       1.50583925, 1.12594458, 1.0838104 , 1.03984429, 1.05953744,\n",
            "       1.36523929, 1.13144035, 1.01900618, 1.08426838, 1.07487978,\n",
            "       1.22349439, 1.19097779, 1.08472636, 1.0767117 , 1.35607969,\n",
            "       1.64048546, 1.16326998, 1.1254866 , 1.01534234, 1.08655828,\n",
            "       1.15937715, 1.06457522, 1.02862377, 1.29722922, 1.04396611,\n",
            "       1.14838562, 1.0487749 , 1.08747424, 1.06617815, 1.0861003 ,\n",
            "       1.0022899 , 1.12594458, 1.23471491, 1.07694069, 1.44126403,\n",
            "       1.0861003 , 1.13395924, 1.12823449, 1.11083123, 1.03274559,\n",
            "       1.06365926, 1.10327456, 1.10831234, 1.1000687 , 1.45019464,\n",
            "       1.04762995, 1.05862148, 1.07373483, 1.0838104 , 1.0396153 ]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.09342798, 1.2441035 , 1.11609801, 1.06801008,\n",
            "       1.07098695, 1.06686512, 1.06411724, 1.05381269, 1.07762766,\n",
            "       1.04076025, 1.01923517, 1.07465079, 1.20036638, 1.04350813,\n",
            "       1.0604534 , 1.04236318, 1.09319899, 1.05381269, 1.12525761,\n",
            "       1.12296771, 1.03068468, 1.15754523, 1.08793222, 1.06869705,\n",
            "       1.01144951, 1.4000458 , 1.10968628, 1.12686054, 1.20563316,\n",
            "       1.18433707, 1.09983971, 1.2466224 , 1.03801237, 1.11564003,\n",
            "       1.02999771, 1.06411724, 1.10487749, 1.2603618 , 1.14220289,\n",
            "       1.16006412, 1.17128463, 1.09594687, 1.10579345, 1.09251202,\n",
            "       1.05930845, 1.51957866, 1.1673918 , 1.05541562, 1.18021525,\n",
            "       1.16326998, 1.00526677, 1.09457293, 1.07716968, 1.08701626,\n",
            "       1.05793451, 1.08106251, 1.14953057, 1.40531257, 1.45088161,\n",
            "       1.12846348, 1.30272498, 1.06778109, 1.13464621, 1.14014197,\n",
            "       1.09022212, 1.11357912, 1.04030227, 1.75727044, 1.1348752 ,\n",
            "       1.09411495, 1.22120449, 1.0977788 , 1.03595145, 1.08976414,\n",
            "       1.1209068 , 1.09800779, 1.10052668, 1.07007099, 1.28028395,\n",
            "       1.0790016 , 1.29013052, 1.37829173, 1.06365926, 1.06388825,\n",
            "       1.04167621, 1.05289673, 1.17242959, 1.07167392, 1.07739867,\n",
            "       1.78337531, 1.08541333, 1.06869705, 1.31302954, 1.03755439,\n",
            "       1.07304786, 1.08884818, 1.0487749 , 1.10350355, 1.0279368 ,\n",
            "       1.03366155, 1.13144035, 1.10396153, 1.03938631, 1.07098695,\n",
            "       1.47858942, 1.06091138, 1.0510648 , 1.07579574, 1.35104191,\n",
            "       1.05724754, 1.05060682, 1.07968857, 1.03595145, 1.08541333,\n",
            "       1.03801237, 1.16372796, 1.09205404, 1.30844974, 1.08037554,\n",
            "       1.00183192, 1.05060682, 1.05678956, 1.28990153, 1.0208381 ,\n",
            "       1.10716739, 1.09686283, 1.15800321, 1.08197847, 1.10670941,\n",
            "       1.08564232, 1.05472865, 1.01122052, 1.15937715, 1.04350813,\n",
            "       1.53423403, 1.07602473, 1.00137394, 1.1417449 , 1.0767117 ,\n",
            "       1.06205633, 1.11060224, 1.11518205, 1.03640943, 1.0370964 ,\n",
            "       1.02060911, 1.10441951, 1.07739867, 1.36730021, 1.09045111,\n",
            "       1.04488207, 1.05907946, 1.35699565, 1.09480192, 1.09045111,\n",
            "       1.07029998, 1.27845203, 1.08793222, 1.25051523, 1.1069384 ,\n",
            "       1.03389054, 1.09892375, 1.07923059, 1.22578429, 1.18731395,\n",
            "       1.12892146, 1.2905885 , 1.07029998, 1.13144035, 1.07419281,\n",
            "       1.2349439 , 1.11678498, 1.0581635 , 1.27272727, 1.06182734,\n",
            "       1.09274101, 1.14357683, 1.13166934, 1.03320357, 1.23150905,\n",
            "       1.01557133, 1.05266774, 1.08770323, 1.09869476, 1.17197161,\n",
            "       1.08266545, 1.07831463, 1.04831692, 1.09136707, 1.04236318,\n",
            "       1.09594687, 1.11128921, 1.06686512, 1.08037554, 1.31531944,\n",
            "       1.53858484, 1.15136249, 1.25005725, 1.07831463, 1.04465308,\n",
            "       1.09823678, 1.14586673, 1.20861003, 1.069842  , 1.12960843,\n",
            "       1.12686054, 1.08312343, 1.01923517, 1.15273643, 1.05129379,\n",
            "       1.03824136, 1.68811541, 1.14586673, 1.02931074, 1.04007328,\n",
            "       1.09869476, 1.04282116, 1.0558736 , 1.00137394, 1.17838333,\n",
            "       1.08770323, 1.08060453, 1.05564461, 1.26402565, 1.02404397,\n",
            "       1.0373254 , 1.08403939, 1.10533547, 1.07281887, 1.02106709,\n",
            "       1.05885047, 1.15960614, 1.16784978, 1.11357912, 1.41905198,\n",
            "       1.10854133, 1.75360659, 1.07579574, 1.98671857, 1.04831692,\n",
            "       1.09983971, 1.1813602 , 1.51454087, 1.07579574, 1.08999313,\n",
            "       1.20059537, 1.09663384, 1.05472865, 1.93771468, 1.09113808,\n",
            "       1.06457522, 1.16670483, 1.07785665, 1.05930845, 1.13624914,\n",
            "       1.14014197, 1.09022212, 1.08060453, 1.20952599, 1.09594687,\n",
            "       1.10327456, 1.04854591, 1.12502862, 1.10945729, 1.08587131,\n",
            "       1.09800779, 1.13373025, 1.11426609, 1.50583925, 1.12594458,\n",
            "       1.0838104 , 1.17151362, 1.08655828, 1.09022212, 1.05953744,\n",
            "       1.13144035, 1.01900618, 1.08426838, 1.07487978, 1.22349439,\n",
            "       1.19097779, 1.08472636, 1.64048546, 1.16326998, 1.1254866 ,\n",
            "       1.1023586 , 1.01534234, 1.11174719, 1.08655828, 1.06457522,\n",
            "       1.02862377, 1.29722922, 1.14838562, 1.0487749 , 1.08747424,\n",
            "       1.0861003 , 1.12067781, 1.0022899 , 1.06801008, 1.23471491,\n",
            "       1.51362491, 1.35928555, 1.07694069, 2.        , 1.44126403,\n",
            "       1.0861003 , 1.13395924, 1.07762766, 1.12823449, 1.11083123,\n",
            "       1.03274559, 1.10831234, 1.1000687 , 1.04762995, 1.05862148,\n",
            "       1.08701626, 1.0838104 , 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.08106251, 1.2441035 , 1.11609801, 1.06801008, 1.02518892,\n",
            "       1.13304328, 1.06411724, 1.05381269, 1.07762766, 1.07465079,\n",
            "       1.20036638, 1.22647126, 1.0604534 , 1.04236318, 1.08770323,\n",
            "       1.05381269, 1.12525761, 1.12296771, 1.15754523, 1.08793222,\n",
            "       1.06869705, 1.01144951, 1.09457293, 1.4000458 , 1.12686054,\n",
            "       1.20563316, 1.09983971, 1.30799176, 1.2466224 , 1.03801237,\n",
            "       1.02999771, 1.10487749, 1.05885047, 1.2603618 , 1.14220289,\n",
            "       1.16006412, 1.17128463, 1.09594687, 1.10579345, 1.09251202,\n",
            "       1.05930845, 1.10373254, 1.11380811, 1.02953973, 1.51957866,\n",
            "       1.04373712, 1.25166018, 1.1673918 , 1.05541562, 1.18021525,\n",
            "       1.10029769, 1.00526677, 1.09457293, 1.07716968, 1.08701626,\n",
            "       1.05793451, 1.08106251, 1.05449966, 1.07190291, 1.14953057,\n",
            "       1.40531257, 1.12846348, 1.11266316, 1.30272498, 1.06778109,\n",
            "       1.13464621, 1.14014197, 1.09022212, 1.11357912, 1.75727044,\n",
            "       1.09411495, 1.22120449, 1.08197847, 1.10029769, 1.0977788 ,\n",
            "       1.03595145, 1.08976414, 1.1209068 , 1.07007099, 1.28028395,\n",
            "       1.0790016 , 1.29013052, 1.37829173, 1.06365926, 1.06388825,\n",
            "       1.04167621, 1.10121365, 1.05289673, 1.17242959, 1.07167392,\n",
            "       1.07739867, 1.78337531, 1.08541333, 1.06869705, 1.29379437,\n",
            "       1.03755439, 1.07304786, 1.07098695, 1.08884818, 1.09136707,\n",
            "       1.0487749 , 1.10350355, 1.0279368 , 1.03366155, 1.13144035,\n",
            "       1.10396153, 1.03938631, 1.07098695, 1.47858942, 1.06091138,\n",
            "       1.0510648 , 1.07579574, 1.30776277, 1.35104191, 1.05724754,\n",
            "       1.05060682, 1.03663842, 1.07968857, 1.03595145, 1.19853446,\n",
            "       1.08541333, 1.03366155, 1.09205404, 1.30844974, 1.09892375,\n",
            "       1.08037554, 1.00183192, 1.05060682, 1.86764369, 1.05678956,\n",
            "       1.28990153, 1.0208381 , 1.10716739, 1.09686283, 1.05999542,\n",
            "       1.05472865, 1.15800321, 1.08197847, 1.31669338, 1.07281887,\n",
            "       1.08564232, 1.09663384, 1.15937715, 1.04350813, 1.10579345,\n",
            "       1.07602473, 1.00137394, 1.1417449 , 1.07625372, 1.0767117 ,\n",
            "       1.11060224, 1.11518205, 1.03640943, 1.0370964 , 1.10441951,\n",
            "       1.07739867, 1.36730021, 1.08861919, 1.09045111, 1.05907946,\n",
            "       1.35699565, 1.09045111, 1.03572246, 1.07029998, 1.27845203,\n",
            "       1.08793222, 1.14815663, 1.12846348, 1.03389054, 1.09892375,\n",
            "       1.07923059, 1.22578429, 1.18731395, 1.12892146, 1.2905885 ,\n",
            "       1.07281887, 1.13144035, 1.07419281, 1.2349439 , 1.1046485 ,\n",
            "       1.11678498, 1.0581635 , 1.27272727, 1.48477215, 1.09274101,\n",
            "       1.13166934, 1.16487291, 1.26929242, 1.03320357, 1.01557133,\n",
            "       1.05266774, 1.08770323, 1.09869476, 1.17197161, 1.08266545,\n",
            "       1.07831463, 1.04831692, 1.03915732, 1.09136707, 1.04236318,\n",
            "       1.14678269, 1.09594687, 1.11128921, 1.06686512, 1.53858484,\n",
            "       1.15136249, 1.25005725, 1.04465308, 1.09823678, 1.12960843,\n",
            "       1.12686054, 1.01923517, 1.15273643, 1.05129379, 1.03824136,\n",
            "       1.02931074, 1.04007328, 1.09869476, 1.04282116, 1.00137394,\n",
            "       1.17838333, 1.08907717, 1.08770323, 1.08152049, 1.05564461,\n",
            "       1.26402565, 1.02404397, 1.0373254 , 1.08403939, 1.10533547,\n",
            "       1.12983742, 1.05885047, 1.15960614, 1.16784978, 1.11174719,\n",
            "       1.11357912, 1.41905198, 1.10602244, 1.10854133, 1.75360659,\n",
            "       1.07579574, 1.98671857, 1.04831692, 1.09983971, 1.51454087,\n",
            "       1.07579574, 1.08999313, 1.20059537, 1.05472865, 1.93771468,\n",
            "       1.09113808, 1.06457522, 1.07785665, 1.05930845, 1.13624914,\n",
            "       1.14014197, 1.09022212, 1.08060453, 1.08106251, 1.04854591,\n",
            "       1.12502862, 1.08587131, 1.09800779, 1.11426609, 1.09846577,\n",
            "       1.50583925, 1.12594458, 1.0838104 , 1.17151362, 1.03984429,\n",
            "       1.09022212, 1.36523929, 1.13144035, 1.01900618, 1.08426838,\n",
            "       1.07487978, 1.22349439, 1.19097779, 1.08472636, 1.0767117 ,\n",
            "       1.1254866 , 1.01534234, 1.11174719, 1.08655828, 1.15937715,\n",
            "       1.06457522, 1.29722922, 1.04396611, 1.14838562, 1.08747424,\n",
            "       1.06617815, 1.0861003 , 1.12067781, 1.0022899 , 1.12594458,\n",
            "       1.06801008, 1.23471491, 1.51362491, 1.35928555, 1.07694069,\n",
            "       2.        , 1.44126403, 1.0861003 , 1.13395924, 1.07762766,\n",
            "       1.12823449, 1.11083123, 1.03274559, 1.06365926, 1.10327456,\n",
            "       1.10831234, 1.1000687 , 1.45019464, 1.04762995, 1.05862148,\n",
            "       1.07373483, 1.08701626, 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.08106251, 1.2441035 ,\n",
            "       1.11609801, 1.06801008, 1.13304328, 1.07098695, 1.06686512,\n",
            "       1.06411724, 1.05381269, 1.04076025, 1.01923517, 1.20036638,\n",
            "       1.22647126, 1.04350813, 1.08770323, 1.09319899, 1.05381269,\n",
            "       1.12525761, 1.12296771, 1.03068468, 1.15754523, 1.08793222,\n",
            "       1.06869705, 1.01144951, 1.09457293, 1.4000458 , 1.10968628,\n",
            "       1.12686054, 1.20563316, 1.18433707, 1.09983971, 1.30799176,\n",
            "       1.2466224 , 1.11564003, 1.02999771, 1.06411724, 1.10487749,\n",
            "       1.05885047, 1.0883902 , 1.2603618 , 1.16006412, 1.09594687,\n",
            "       1.10579345, 1.09251202, 1.10373254, 1.11380811, 1.51957866,\n",
            "       1.25166018, 1.1673918 , 1.21685368, 1.05541562, 1.18021525,\n",
            "       1.16326998, 1.00526677, 1.09457293, 1.00549576, 1.07716968,\n",
            "       1.08701626, 1.05793451, 1.08106251, 1.05449966, 1.14953057,\n",
            "       1.40531257, 1.45088161, 1.12846348, 1.11266316, 1.30272498,\n",
            "       1.06778109, 1.13464621, 1.14014197, 1.11357912, 1.04030227,\n",
            "       1.75727044, 1.1348752 , 1.09411495, 1.10029769, 1.0977788 ,\n",
            "       1.08976414, 1.1209068 , 1.09800779, 1.10052668, 1.02610488,\n",
            "       1.28028395, 1.0790016 , 1.29013052, 1.06388825, 1.15846119,\n",
            "       1.05289673, 1.17242959, 1.07167392, 1.07739867, 1.78337531,\n",
            "       1.08541333, 1.06869705, 1.31302954, 1.03755439, 1.07304786,\n",
            "       1.07098695, 1.08884818, 1.09136707, 1.0279368 , 1.03366155,\n",
            "       1.13144035, 1.10396153, 1.03938631, 1.19601557, 1.06091138,\n",
            "       1.05724754, 1.05060682, 1.03663842, 1.07968857, 1.03595145,\n",
            "       1.19853446, 1.03801237, 1.16372796, 1.09205404, 1.09892375,\n",
            "       1.08037554, 1.05060682, 1.86764369, 1.09754981, 1.0208381 ,\n",
            "       1.10716739, 1.09686283, 1.05999542, 1.15800321, 1.08197847,\n",
            "       1.10670941, 1.07281887, 1.08564232, 1.05472865, 1.01122052,\n",
            "       1.15937715, 1.04350813, 1.53423403, 1.10579345, 1.07602473,\n",
            "       1.00137394, 1.1417449 , 1.07625372, 1.0767117 , 1.06205633,\n",
            "       1.03640943, 1.0370964 , 1.02060911, 1.10441951, 1.07739867,\n",
            "       1.36730021, 1.08861919, 1.09045111, 1.04488207, 1.05907946,\n",
            "       1.35699565, 1.09480192, 1.09045111, 1.03572246, 1.27845203,\n",
            "       1.08793222, 1.25051523, 1.14815663, 1.06778109, 1.1069384 ,\n",
            "       1.12846348, 1.03389054, 1.09892375, 1.11930387, 1.07923059,\n",
            "       1.22578429, 1.18731395, 1.12892146, 1.2905885 , 1.07281887,\n",
            "       1.07029998, 1.13144035, 1.46072819, 1.07419281, 1.2349439 ,\n",
            "       1.0581635 , 1.06182734, 1.48477215, 1.09274101, 1.14357683,\n",
            "       1.0767117 , 1.03320357, 1.23150905, 1.01557133, 1.05266774,\n",
            "       1.08770323, 1.17197161, 1.08266545, 1.04831692, 1.03915732,\n",
            "       1.14678269, 1.09594687, 1.08037554, 1.31531944, 1.53858484,\n",
            "       1.25005725, 1.07831463, 1.04465308, 1.09823678, 1.14586673,\n",
            "       1.20861003, 1.069842  , 1.12960843, 1.12686054, 1.08312343,\n",
            "       1.01923517, 1.15273643, 1.05129379, 1.03824136, 1.68811541,\n",
            "       1.14586673, 1.02931074, 1.09869476, 1.15456835, 1.0558736 ,\n",
            "       1.00137394, 1.08907717, 1.0977788 , 1.08152049, 1.08060453,\n",
            "       1.26402565, 1.02404397, 1.0373254 , 1.10533547, 1.12983742,\n",
            "       1.07281887, 1.02106709, 1.05885047, 1.15960614, 1.16784978,\n",
            "       1.11357912, 1.41905198, 1.10602244, 1.75360659, 1.07579574,\n",
            "       1.04831692, 1.09983971, 1.1813602 , 1.51454087, 1.07579574,\n",
            "       1.08999313, 1.20059537, 1.09663384, 1.05472865, 1.93771468,\n",
            "       1.09113808, 1.06457522, 1.16670483, 1.07785665, 1.05930845,\n",
            "       1.13624914, 1.14014197, 1.09022212, 1.20952599, 1.09594687,\n",
            "       1.10327456, 1.12502862, 1.10945729, 1.08587131, 1.09800779,\n",
            "       1.13373025, 1.11426609, 1.09846577, 1.50583925, 1.12594458,\n",
            "       1.0838104 , 1.08655828, 1.03984429, 1.09022212, 1.05953744,\n",
            "       1.36523929, 1.01900618, 1.08426838, 1.07487978, 1.22349439,\n",
            "       1.19097779, 1.0767117 , 1.35607969, 1.64048546, 1.16326998,\n",
            "       1.1254866 , 1.1023586 , 1.01534234, 1.11174719, 1.08655828,\n",
            "       1.15937715, 1.02862377, 1.04396611, 1.14838562, 1.0487749 ,\n",
            "       1.08747424, 1.06617815, 1.12067781, 1.0022899 , 1.12594458,\n",
            "       1.06801008, 1.23471491, 1.51362491, 1.35928555, 1.07694069,\n",
            "       2.        , 1.44126403, 1.0861003 , 1.12823449, 1.11083123,\n",
            "       1.03274559, 1.06365926, 1.10327456, 1.45019464, 1.04762995,\n",
            "       1.08701626, 1.0838104 , 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.08106251, 1.2441035 ,\n",
            "       1.11609801, 1.06801008, 1.02518892, 1.13304328, 1.07098695,\n",
            "       1.06686512, 1.06411724, 1.05381269, 1.07762766, 1.04076025,\n",
            "       1.01923517, 1.07465079, 1.04350813, 1.0604534 , 1.04236318,\n",
            "       1.08770323, 1.09319899, 1.05381269, 1.12525761, 1.12296771,\n",
            "       1.03068468, 1.15754523, 1.08793222, 1.06869705, 1.01144951,\n",
            "       1.09457293, 1.4000458 , 1.10968628, 1.20563316, 1.18433707,\n",
            "       1.09983971, 1.30799176, 1.2466224 , 1.03801237, 1.11564003,\n",
            "       1.06411724, 1.05885047, 1.0883902 , 1.2603618 , 1.14220289,\n",
            "       1.16006412, 1.17128463, 1.09594687, 1.10579345, 1.05930845,\n",
            "       1.10373254, 1.11380811, 1.02953973, 1.04373712, 1.1673918 ,\n",
            "       1.21685368, 1.10029769, 1.16326998, 1.00526677, 1.09457293,\n",
            "       1.00549576, 1.07716968, 1.08701626, 1.05793451, 1.08106251,\n",
            "       1.05449966, 1.07190291, 1.40531257, 1.45088161, 1.30272498,\n",
            "       1.14014197, 1.09022212, 1.11357912, 1.04030227, 1.75727044,\n",
            "       1.1348752 , 1.09411495, 1.22120449, 1.08197847, 1.0977788 ,\n",
            "       1.03595145, 1.1209068 , 1.09800779, 1.10052668, 1.02610488,\n",
            "       1.07007099, 1.37829173, 1.06365926, 1.06388825, 1.04167621,\n",
            "       1.15846119, 1.10121365, 1.05289673, 1.07167392, 1.07739867,\n",
            "       1.06869705, 1.31302954, 1.29379437, 1.03755439, 1.07304786,\n",
            "       1.07098695, 1.08884818, 1.0487749 , 1.10350355, 1.03366155,\n",
            "       1.10396153, 1.03938631, 1.07098695, 1.19601557, 1.47858942,\n",
            "       1.06091138, 1.0510648 , 1.07579574, 1.30776277, 1.35104191,\n",
            "       1.07968857, 1.03595145, 1.19853446, 1.08541333, 1.03801237,\n",
            "       1.03366155, 1.16372796, 1.09205404, 1.30844974, 1.09892375,\n",
            "       1.08037554, 1.00183192, 1.05060682, 1.09754981, 1.05678956,\n",
            "       1.28990153, 1.09686283, 1.05472865, 1.15800321, 1.10670941,\n",
            "       1.31669338, 1.07281887, 1.08564232, 1.05472865, 1.01122052,\n",
            "       1.09663384, 1.04350813, 1.53423403, 1.10579345, 1.1417449 ,\n",
            "       1.07625372, 1.06205633, 1.11060224, 1.11518205, 1.03640943,\n",
            "       1.0370964 , 1.02060911, 1.07739867, 1.09045111, 1.04488207,\n",
            "       1.05907946, 1.35699565, 1.09480192, 1.09045111, 1.03572246,\n",
            "       1.07029998, 1.08793222, 1.25051523, 1.14815663, 1.06778109,\n",
            "       1.1069384 , 1.12846348, 1.03389054, 1.11930387, 1.12892146,\n",
            "       1.07281887, 1.07029998, 1.46072819, 1.2349439 , 1.1046485 ,\n",
            "       1.11678498, 1.0581635 , 1.27272727, 1.06182734, 1.48477215,\n",
            "       1.14357683, 1.13166934, 1.16487291, 1.26929242, 1.0767117 ,\n",
            "       1.23150905, 1.01557133, 1.05266774, 1.08770323, 1.09869476,\n",
            "       1.17197161, 1.08266545, 1.07831463, 1.04831692, 1.09136707,\n",
            "       1.04236318, 1.09594687, 1.11128921, 1.06686512, 1.08037554,\n",
            "       1.31531944, 1.15136249, 1.25005725, 1.07831463, 1.09823678,\n",
            "       1.14586673, 1.20861003, 1.069842  , 1.12960843, 1.12686054,\n",
            "       1.08312343, 1.01923517, 1.15273643, 1.05129379, 1.68811541,\n",
            "       1.14586673, 1.02931074, 1.04007328, 1.15456835, 1.04282116,\n",
            "       1.0558736 , 1.00137394, 1.17838333, 1.08907717, 1.08770323,\n",
            "       1.0977788 , 1.08152049, 1.08060453, 1.05564461, 1.26402565,\n",
            "       1.02404397, 1.0373254 , 1.08403939, 1.12983742, 1.07281887,\n",
            "       1.02106709, 1.16784978, 1.11174719, 1.41905198, 1.10602244,\n",
            "       1.10854133, 1.07579574, 1.98671857, 1.04831692, 1.09983971,\n",
            "       1.1813602 , 1.51454087, 1.07579574, 1.20059537, 1.09663384,\n",
            "       1.05472865, 1.16670483, 1.07785665, 1.05930845, 1.13624914,\n",
            "       1.09022212, 1.08060453, 1.08106251, 1.20952599, 1.09594687,\n",
            "       1.10327456, 1.04854591, 1.12502862, 1.10945729, 1.09800779,\n",
            "       1.13373025, 1.11426609, 1.09846577, 1.50583925, 1.17151362,\n",
            "       1.08655828, 1.03984429, 1.05953744, 1.13144035, 1.01900618,\n",
            "       1.22349439, 1.19097779, 1.08472636, 1.35607969, 1.64048546,\n",
            "       1.16326998, 1.1254866 , 1.1023586 , 1.01534234, 1.11174719,\n",
            "       1.08655828, 1.15937715, 1.06457522, 1.02862377, 1.29722922,\n",
            "       1.04396611, 1.14838562, 1.0487749 , 1.06617815, 1.0861003 ,\n",
            "       1.12067781, 1.12594458, 1.06801008, 1.35928555, 1.07694069,\n",
            "       2.        , 1.44126403, 1.0861003 , 1.13395924, 1.07762766,\n",
            "       1.12823449, 1.11083123, 1.03274559, 1.06365926, 1.10831234,\n",
            "       1.1000687 , 1.45019464, 1.04762995, 1.05862148, 1.07373483,\n",
            "       1.08701626, 1.0838104 , 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.08106251, 1.2441035 ,\n",
            "       1.02518892, 1.07098695, 1.06686512, 1.07762766, 1.04076025,\n",
            "       1.01923517, 1.07465079, 1.20036638, 1.22647126, 1.04350813,\n",
            "       1.0604534 , 1.04236318, 1.09319899, 1.12525761, 1.12296771,\n",
            "       1.03068468, 1.08793222, 1.09457293, 1.4000458 , 1.10968628,\n",
            "       1.12686054, 1.20563316, 1.18433707, 1.2466224 , 1.03801237,\n",
            "       1.11564003, 1.02999771, 1.06411724, 1.10487749, 1.0883902 ,\n",
            "       1.14220289, 1.17128463, 1.09594687, 1.09251202, 1.05930845,\n",
            "       1.02953973, 1.51957866, 1.04373712, 1.25166018, 1.21685368,\n",
            "       1.05541562, 1.18021525, 1.10029769, 1.16326998, 1.09457293,\n",
            "       1.00549576, 1.07716968, 1.08701626, 1.05449966, 1.07190291,\n",
            "       1.14953057, 1.45088161, 1.12846348, 1.11266316, 1.06778109,\n",
            "       1.13464621, 1.14014197, 1.09022212, 1.04030227, 1.75727044,\n",
            "       1.1348752 , 1.22120449, 1.08197847, 1.10029769, 1.0977788 ,\n",
            "       1.03595145, 1.08976414, 1.1209068 , 1.09800779, 1.10052668,\n",
            "       1.02610488, 1.07007099, 1.28028395, 1.0790016 , 1.29013052,\n",
            "       1.37829173, 1.06365926, 1.06388825, 1.04167621, 1.15846119,\n",
            "       1.10121365, 1.17242959, 1.07167392, 1.07739867, 1.78337531,\n",
            "       1.08541333, 1.06869705, 1.31302954, 1.29379437, 1.09136707,\n",
            "       1.0487749 , 1.10350355, 1.0279368 , 1.03366155, 1.13144035,\n",
            "       1.03938631, 1.07098695, 1.19601557, 1.47858942, 1.0510648 ,\n",
            "       1.07579574, 1.30776277, 1.35104191, 1.05724754, 1.05060682,\n",
            "       1.03663842, 1.03595145, 1.19853446, 1.08541333, 1.03801237,\n",
            "       1.03366155, 1.16372796, 1.09205404, 1.30844974, 1.08037554,\n",
            "       1.00183192, 1.05060682, 1.86764369, 1.09754981, 1.05678956,\n",
            "       1.28990153, 1.0208381 , 1.10716739, 1.05999542, 1.05472865,\n",
            "       1.08197847, 1.10670941, 1.31669338, 1.07281887, 1.05472865,\n",
            "       1.01122052, 1.09663384, 1.15937715, 1.53423403, 1.07602473,\n",
            "       1.00137394, 1.07625372, 1.0767117 , 1.06205633, 1.11060224,\n",
            "       1.11518205, 1.03640943, 1.02060911, 1.10441951, 1.36730021,\n",
            "       1.08861919, 1.09045111, 1.04488207, 1.05907946, 1.35699565,\n",
            "       1.09480192, 1.03572246, 1.07029998, 1.27845203, 1.25051523,\n",
            "       1.06778109, 1.1069384 , 1.09892375, 1.11930387, 1.07923059,\n",
            "       1.22578429, 1.18731395, 1.2905885 , 1.07029998, 1.13144035,\n",
            "       1.46072819, 1.07419281, 1.1046485 , 1.11678498, 1.27272727,\n",
            "       1.06182734, 1.48477215, 1.09274101, 1.14357683, 1.13166934,\n",
            "       1.16487291, 1.26929242, 1.0767117 , 1.03320357, 1.23150905,\n",
            "       1.05266774, 1.09869476, 1.08266545, 1.07831463, 1.04831692,\n",
            "       1.03915732, 1.09136707, 1.04236318, 1.14678269, 1.09594687,\n",
            "       1.11128921, 1.06686512, 1.08037554, 1.31531944, 1.53858484,\n",
            "       1.15136249, 1.07831463, 1.04465308, 1.09823678, 1.14586673,\n",
            "       1.20861003, 1.069842  , 1.12960843, 1.12686054, 1.08312343,\n",
            "       1.01923517, 1.03824136, 1.68811541, 1.14586673, 1.02931074,\n",
            "       1.04007328, 1.09869476, 1.15456835, 1.04282116, 1.0558736 ,\n",
            "       1.00137394, 1.17838333, 1.08770323, 1.0977788 , 1.08060453,\n",
            "       1.05564461, 1.26402565, 1.02404397, 1.08403939, 1.10533547,\n",
            "       1.07281887, 1.02106709, 1.05885047, 1.15960614, 1.11174719,\n",
            "       1.11357912, 1.10854133, 1.75360659, 1.07579574, 1.98671857,\n",
            "       1.09983971, 1.1813602 , 1.08999313, 1.20059537, 1.09663384,\n",
            "       1.05472865, 1.93771468, 1.09113808, 1.06457522, 1.16670483,\n",
            "       1.07785665, 1.13624914, 1.14014197, 1.08060453, 1.08106251,\n",
            "       1.20952599, 1.09594687, 1.10327456, 1.04854591, 1.12502862,\n",
            "       1.10945729, 1.08587131, 1.09800779, 1.13373025, 1.11426609,\n",
            "       1.09846577, 1.50583925, 1.12594458, 1.0838104 , 1.17151362,\n",
            "       1.08655828, 1.03984429, 1.09022212, 1.05953744, 1.36523929,\n",
            "       1.13144035, 1.01900618, 1.08426838, 1.07487978, 1.22349439,\n",
            "       1.08472636, 1.0767117 , 1.35607969, 1.64048546, 1.16326998,\n",
            "       1.1254866 , 1.1023586 , 1.01534234, 1.11174719, 1.15937715,\n",
            "       1.06457522, 1.02862377, 1.29722922, 1.14838562, 1.0487749 ,\n",
            "       1.08747424, 1.06617815, 1.0861003 , 1.0022899 , 1.06801008,\n",
            "       1.23471491, 1.51362491, 1.35928555, 1.07694069, 2.        ,\n",
            "       1.44126403, 1.0861003 , 1.13395924, 1.07762766, 1.12823449,\n",
            "       1.03274559, 1.10327456, 1.10831234, 1.1000687 , 1.05862148,\n",
            "       1.07373483, 1.0838104 , 1.0396153 , 1.06663613, 1.01557133]),)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 393, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1131, in _validate_input\n",
            "    self._label_binarizer.fit(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 301, in fit\n",
            "    self.classes_ = unique_labels(y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 101, in unique_labels\n",
            "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
            "ValueError: Unknown label type: (array([1.05198076, 1.10877032, 1.09342798, 1.11609801, 1.06801008,\n",
            "       1.02518892, 1.13304328, 1.07098695, 1.06686512, 1.06411724,\n",
            "       1.05381269, 1.07762766, 1.04076025, 1.01923517, 1.07465079,\n",
            "       1.20036638, 1.22647126, 1.04350813, 1.0604534 , 1.04236318,\n",
            "       1.08770323, 1.09319899, 1.05381269, 1.03068468, 1.15754523,\n",
            "       1.06869705, 1.01144951, 1.10968628, 1.12686054, 1.18433707,\n",
            "       1.09983971, 1.30799176, 1.03801237, 1.11564003, 1.02999771,\n",
            "       1.06411724, 1.10487749, 1.05885047, 1.0883902 , 1.2603618 ,\n",
            "       1.14220289, 1.16006412, 1.17128463, 1.10579345, 1.09251202,\n",
            "       1.05930845, 1.10373254, 1.11380811, 1.02953973, 1.51957866,\n",
            "       1.04373712, 1.25166018, 1.1673918 , 1.21685368, 1.05541562,\n",
            "       1.18021525, 1.10029769, 1.16326998, 1.00526677, 1.00549576,\n",
            "       1.05793451, 1.08106251, 1.07190291, 1.14953057, 1.40531257,\n",
            "       1.45088161, 1.12846348, 1.11266316, 1.30272498, 1.06778109,\n",
            "       1.13464621, 1.09022212, 1.11357912, 1.04030227, 1.1348752 ,\n",
            "       1.09411495, 1.22120449, 1.08197847, 1.10029769, 1.03595145,\n",
            "       1.08976414, 1.09800779, 1.10052668, 1.02610488, 1.07007099,\n",
            "       1.28028395, 1.0790016 , 1.29013052, 1.37829173, 1.06365926,\n",
            "       1.04167621, 1.15846119, 1.10121365, 1.05289673, 1.17242959,\n",
            "       1.78337531, 1.08541333, 1.31302954, 1.29379437, 1.03755439,\n",
            "       1.07304786, 1.07098695, 1.08884818, 1.09136707, 1.0487749 ,\n",
            "       1.10350355, 1.0279368 , 1.13144035, 1.10396153, 1.07098695,\n",
            "       1.19601557, 1.47858942, 1.06091138, 1.0510648 , 1.07579574,\n",
            "       1.30776277, 1.35104191, 1.05724754, 1.05060682, 1.03663842,\n",
            "       1.07968857, 1.08541333, 1.03801237, 1.03366155, 1.16372796,\n",
            "       1.30844974, 1.09892375, 1.00183192, 1.86764369, 1.09754981,\n",
            "       1.05678956, 1.28990153, 1.0208381 , 1.10716739, 1.09686283,\n",
            "       1.05999542, 1.05472865, 1.15800321, 1.08197847, 1.10670941,\n",
            "       1.31669338, 1.08564232, 1.05472865, 1.01122052, 1.09663384,\n",
            "       1.15937715, 1.04350813, 1.53423403, 1.10579345, 1.07602473,\n",
            "       1.00137394, 1.1417449 , 1.0767117 , 1.06205633, 1.11060224,\n",
            "       1.11518205, 1.0370964 , 1.02060911, 1.10441951, 1.07739867,\n",
            "       1.36730021, 1.08861919, 1.04488207, 1.09480192, 1.09045111,\n",
            "       1.07029998, 1.27845203, 1.08793222, 1.25051523, 1.14815663,\n",
            "       1.06778109, 1.1069384 , 1.12846348, 1.03389054, 1.09892375,\n",
            "       1.11930387, 1.07923059, 1.22578429, 1.18731395, 1.12892146,\n",
            "       1.2905885 , 1.07281887, 1.07029998, 1.13144035, 1.46072819,\n",
            "       1.07419281, 1.2349439 , 1.1046485 , 1.11678498, 1.0581635 ,\n",
            "       1.27272727, 1.06182734, 1.09274101, 1.14357683, 1.13166934,\n",
            "       1.16487291, 1.26929242, 1.0767117 , 1.03320357, 1.23150905,\n",
            "       1.01557133, 1.08770323, 1.09869476, 1.17197161, 1.07831463,\n",
            "       1.03915732, 1.09136707, 1.04236318, 1.14678269, 1.11128921,\n",
            "       1.06686512, 1.08037554, 1.31531944, 1.53858484, 1.15136249,\n",
            "       1.25005725, 1.07831463, 1.04465308, 1.14586673, 1.20861003,\n",
            "       1.069842  , 1.08312343, 1.15273643, 1.05129379, 1.03824136,\n",
            "       1.68811541, 1.14586673, 1.04007328, 1.09869476, 1.15456835,\n",
            "       1.04282116, 1.0558736 , 1.17838333, 1.08907717, 1.08770323,\n",
            "       1.0977788 , 1.08152049, 1.08060453, 1.05564461, 1.0373254 ,\n",
            "       1.08403939, 1.10533547, 1.12983742, 1.07281887, 1.02106709,\n",
            "       1.05885047, 1.15960614, 1.16784978, 1.11174719, 1.11357912,\n",
            "       1.41905198, 1.10602244, 1.10854133, 1.75360659, 1.98671857,\n",
            "       1.04831692, 1.1813602 , 1.51454087, 1.07579574, 1.08999313,\n",
            "       1.09663384, 1.93771468, 1.09113808, 1.06457522, 1.16670483,\n",
            "       1.05930845, 1.14014197, 1.09022212, 1.08060453, 1.08106251,\n",
            "       1.20952599, 1.09594687, 1.10327456, 1.04854591, 1.10945729,\n",
            "       1.08587131, 1.13373025, 1.12594458, 1.0838104 , 1.17151362,\n",
            "       1.08655828, 1.09022212, 1.05953744, 1.36523929, 1.13144035,\n",
            "       1.08426838, 1.07487978, 1.19097779, 1.08472636, 1.0767117 ,\n",
            "       1.35607969, 1.64048546, 1.16326998, 1.1023586 , 1.08655828,\n",
            "       1.06457522, 1.02862377, 1.29722922, 1.04396611, 1.0487749 ,\n",
            "       1.08747424, 1.0861003 , 1.12067781, 1.0022899 , 1.12594458,\n",
            "       1.23471491, 1.51362491, 1.13395924, 1.07762766, 1.11083123,\n",
            "       1.06365926, 1.10327456, 1.10831234, 1.1000687 , 1.45019464,\n",
            "       1.04762995, 1.05862148, 1.07373483, 1.08701626, 1.0838104 ]),)\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-209-d93521d17351>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgrid_model_MLP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo_MLP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hidden_layer_sizes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"learning_rate_init\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi_MAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#\"hidden_layer_sizes\":np.arange(1,5),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgrid_model_MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrainFTf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Utilizando la métrica\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_model_MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"la mejor puntuación obtenida es:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_model_MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# of out will be done in `_insert_error_scores`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m                     \u001b[0m_insert_error_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_insert_error_scores\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuccessful_score\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All estimators failed to fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccessful_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: All estimators failed to fit"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-9.**\n",
        "Con los mejores valores de los hiperparámetros encontrados realiza un análisis de la importancia de los factores. Muestra un diagrama de barras de los resultados e incluye tus conclusiones."
      ],
      "metadata": {
        "id": "mASNrZWs8JTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,x in enumerate(scaled_Y_train_fit_transform):\n",
        "    scaled_Y_train_fit_transform[i]=x.astype('int')"
      ],
      "metadata": {
        "id": "PidSycymq-PQ"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scaled_Y_train_fit_transform)"
      ],
      "metadata": {
        "id": "j1idGi9lv8ls",
        "outputId": "59480d4f-9643-4ff2-86f2-43cfd4af4acb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 4. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 4. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n",
            " 4. 0. 0. 0. 4. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "cc_bnd2Jiv95",
        "outputId": "4bcc41e2-b55e-4378-8a46-1a97f32cc718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(z)"
      ],
      "metadata": {
        "id": "DWG-5x_Axqxs",
        "outputId": "42a46087-e664-49a7-e483-086c260d44c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2126  168  762  306  167 1834  157  403  230  391  297  347 1292  293\n",
            "  333 1275 1613  814  140  340 2119  508 1200  621  705  732 1578  477\n",
            "  269  630  305  559  316  123  152 3430  436 1513  342  278  435  475\n",
            " 2278  985   59  998 1542  119  437  646  395 1101  340 2256  283  220\n",
            "  393  327  319   32  240  699  413  220  471  379  305    9  301  576\n",
            "  441  275 1779 1276  422  287 1146  240  348  456   93  375  327  392\n",
            "  414  392  557  100  289 1356  348  300 1086  774  563   58 1564  465\n",
            "  335  482  236 3798  884  885  774 1331   92  606  156  399  476  248\n",
            " 2342  475  447  357  327  697  594  106 1052  126  363  211  590  134\n",
            "  462  185 1661  403  514  447  268  319  569  760  291 1233  363  236\n",
            "  740  375 2252  907 3316  131  408  924 3300  347 1353  516 1609  408\n",
            "   15  740  196  642  181 1392  351  584  460  454  323 1292  323  176\n",
            " 1905  101  309  397  604  246  445   15  470  660  788  367  981 4318\n",
            "  630  530  363  537  361  684  123  398  239  493  382  453  244  387\n",
            "  263  621  463  351   93  428  404  277  440  132  461  183  656  432\n",
            "  280  351  143  408 1035  180  459  570  390  361  489 2806  593   77\n",
            " 1185  315 1349  393   33  398  401  287  650 1975  165  497  459  340\n",
            "  471  505  389  266  538  438  537  307  724  796  191 1395  365  298\n",
            " 1354  501  377  360  166  484 1978  175  253  389  977  428  346  379\n",
            "  316  429  355  328  251  306 1075 1604  436  187  488  166  259  598\n",
            "  995  169 1756  154  143  271  248 1225 2099  314 1250  559  385   17\n",
            "  361  348  467  309  920 2602 1307  460 1162  483  237  729  583  431\n",
            "  448  137 2361  469  708  504  801 1008  355  262 1790  403  175  252\n",
            "  439  497  194 4376  375  222  280  288  865  305  341  194  232  506\n",
            " 1020  570  340  583  487 1716  445  316 3014  546  280 4104  876  742\n",
            "  268 1034  555  384  345  662  349  403  446  432  706  289  265  233\n",
            "  497  341  505  563  221  441  636   99  843  200  328  628  701  389\n",
            "  757  722  440  370  472  975  583  199  422  492  322  342  279  420\n",
            "  705 1936  469  704 1016  392  411  403]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(scaled_Y_train_fit_transform)"
      ],
      "metadata": {
        "id": "KtAnLTVJxwwb",
        "outputId": "37579993-07e7-466e-aad6-58d62c19f4ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.48477215 0.03640943 0.17242959 0.06801008 0.03618044 0.41790703\n",
            " 0.03389054 0.09022212 0.05060682 0.08747424 0.06594916 0.07739867\n",
            " 0.29379437 0.0650332  0.07419281 0.28990153 0.36730021 0.18433707\n",
            " 0.02999771 0.07579574 0.48316922 0.11426609 0.27272727 0.14014197\n",
            " 0.15937715 0.16555988 0.35928555 0.10716739 0.05953744 0.14220289\n",
            " 0.06778109 0.12594458 0.07029998 0.02610488 0.03274559 0.78337531\n",
            " 0.0977788  0.34440119 0.07625372 0.06159835 0.09754981 0.10670941\n",
            " 0.51957866 0.22349439 0.01144951 0.22647126 0.35104191 0.02518892\n",
            " 0.09800779 0.14586673 0.0883902  0.25005725 0.07579574 0.51454087\n",
            " 0.0627433  0.04831692 0.08793222 0.07281887 0.07098695 0.00526677\n",
            " 0.05289673 0.15800321 0.09251202 0.04831692 0.10579345 0.08472636\n",
            " 0.06778109 0.         0.06686512 0.12983742 0.09892375 0.06091138\n",
            " 0.40531257 0.29013052 0.09457293 0.06365926 0.2603618  0.05289673\n",
            " 0.07762766 0.1023586  0.01923517 0.0838104  0.07281887 0.08770323\n",
            " 0.09274101 0.08770323 0.1254866  0.0208381  0.06411724 0.30844974\n",
            " 0.07762766 0.06663613 0.2466224  0.17517747 0.12686054 0.01122052\n",
            " 0.35607969 0.10441951 0.07465079 0.10831234 0.05198076 0.86764369\n",
            " 0.20036638 0.20059537 0.17517747 0.30272498 0.01900618 0.13670712\n",
            " 0.03366155 0.08930616 0.1069384  0.05472865 0.53423403 0.10670941\n",
            " 0.10029769 0.07968857 0.07281887 0.15754523 0.13395924 0.02221204\n",
            " 0.23883673 0.02679185 0.08106251 0.04625601 0.13304328 0.02862377\n",
            " 0.10373254 0.04030227 0.37829173 0.09022212 0.11564003 0.10029769\n",
            " 0.05930845 0.07098695 0.12823449 0.17197161 0.06457522 0.28028395\n",
            " 0.08106251 0.05198076 0.1673918  0.0838104  0.51362491 0.20563316\n",
            " 0.75727044 0.0279368  0.09136707 0.20952599 0.75360659 0.07739867\n",
            " 0.30776277 0.11609801 0.36638425 0.09136707 0.00137394 0.1673918\n",
            " 0.04282116 0.14495077 0.03938631 0.31669338 0.07831463 0.13166934\n",
            " 0.10327456 0.10190062 0.07190291 0.29379437 0.07190291 0.03824136\n",
            " 0.43416533 0.02106709 0.06869705 0.08884818 0.13624914 0.05427067\n",
            " 0.09983971 0.00137394 0.10556446 0.14907259 0.17838333 0.08197847\n",
            " 0.22257843 0.98671857 0.14220289 0.11930387 0.08106251 0.1209068\n",
            " 0.08060453 0.15456835 0.02610488 0.08907717 0.05266774 0.11083123\n",
            " 0.08541333 0.10167163 0.05381269 0.08655828 0.0581635  0.14014197\n",
            " 0.10396153 0.07831463 0.01923517 0.09594687 0.09045111 0.06136936\n",
            " 0.09869476 0.02816579 0.10350355 0.03984429 0.14815663 0.09686283\n",
            " 0.06205633 0.07831463 0.03068468 0.09136707 0.2349439  0.03915732\n",
            " 0.10304557 0.12846348 0.08724525 0.08060453 0.10991527 0.64048546\n",
            " 0.13373025 0.01557133 0.26929242 0.07007099 0.30684681 0.08793222\n",
            " 0.00549576 0.08907717 0.08976414 0.06365926 0.14678269 0.45019464\n",
            " 0.03572246 0.11174719 0.10304557 0.07579574 0.10579345 0.11357912\n",
            " 0.08701626 0.05885047 0.12113579 0.09823678 0.1209068  0.06823907\n",
            " 0.16372796 0.18021525 0.04167621 0.31738035 0.08152049 0.06617815\n",
            " 0.30799176 0.11266316 0.08426838 0.08037554 0.03595145 0.10877032\n",
            " 0.45088161 0.03801237 0.0558736  0.08701626 0.22166247 0.09594687\n",
            " 0.07716968 0.08472636 0.07029998 0.09617586 0.07923059 0.07304786\n",
            " 0.05541562 0.06801008 0.2441035  0.36523929 0.0977788  0.04076025\n",
            " 0.10968628 0.03595145 0.05724754 0.1348752  0.22578429 0.03663842\n",
            " 0.4000458  0.03320357 0.03068468 0.05999542 0.05472865 0.27845203\n",
            " 0.47858942 0.069842   0.28417678 0.12594458 0.0861003  0.00183192\n",
            " 0.08060453 0.07762766 0.10487749 0.06869705 0.20861003 0.59377147\n",
            " 0.29722922 0.10327456 0.26402565 0.10854133 0.05220975 0.16487291\n",
            " 0.13144035 0.09663384 0.10052668 0.02931074 0.53858484 0.10533547\n",
            " 0.16006412 0.11335013 0.1813602  0.22876116 0.07923059 0.05793451\n",
            " 0.40783146 0.09022212 0.03801237 0.05564461 0.09846577 0.11174719\n",
            " 0.04236318 1.         0.0838104  0.0487749  0.06205633 0.06388825\n",
            " 0.19601557 0.06778109 0.07602473 0.04236318 0.0510648  0.11380811\n",
            " 0.23150905 0.12846348 0.07579574 0.13144035 0.10945729 0.39088619\n",
            " 0.09983971 0.07029998 0.68811541 0.12296771 0.06205633 0.93771468\n",
            " 0.19853446 0.16784978 0.05930845 0.23471491 0.12502862 0.08587131\n",
            " 0.07694069 0.14953057 0.07785665 0.09022212 0.1000687  0.09686283\n",
            " 0.15960614 0.06411724 0.05862148 0.05129379 0.11174719 0.07602473\n",
            " 0.11357912 0.12686054 0.04854591 0.09892375 0.14357683 0.02060911\n",
            " 0.19097779 0.04373712 0.07304786 0.1417449  0.15846119 0.08701626\n",
            " 0.17128463 0.16326998 0.09869476 0.08266545 0.10602244 0.22120449\n",
            " 0.13144035 0.04350813 0.09457293 0.11060224 0.07167392 0.07625372\n",
            " 0.06182734 0.09411495 0.15937715 0.44126403 0.10533547 0.15914816\n",
            " 0.23059308 0.08770323 0.09205404 0.09022212]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MejorModelo_MLP = MLPClassifier(hidden_layer_sizes=(20,),\n",
        "                            alpha=0.0001,\n",
        "                            learning_rate_init=0.00001)\n",
        "\n",
        "X_train_ajustado = columnasTransformer.fit(X_train)\n",
        "\n",
        "X_train_ajustado_transformado = X_train_ajustado.transform(X_train)\n",
        "\n",
        "scaler=MinMaxScaler()\n",
        "z = np.array(y_train)\n",
        "z.reshape(1, -1)\n",
        "scaled_Y_train_fit = scaler.fit(z.reshape(-1,1))\n",
        "scaled_Y_train_fit_transform = scaler.transform(z.reshape(-1,1))\n",
        "\n",
        "scaled_Y_train_fit_transform = scaled_Y_train_fit_transform.reshape(-1)\n",
        "\n",
        "MejorModelo_MLP.fit(X_train_ajustado_transformado, y_train)\n",
        "\n",
        "Importancia_Factores = permutation_importance(MejorModelo_MLP, X_train_ajustado_transformado, scaled_Y_train_fit_transform, n_repeats=10)\n",
        "\n",
        "print(Importancia_Factores)"
      ],
      "metadata": {
        "id": "X6HJP9hb8LCp",
        "outputId": "b76a4659-ba07-4cac-9150-4f5840bae20d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-4241eb262830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mMejorModelo_MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_ajustado_transformado\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mImportancia_Factores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpermutation_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMejorModelo_MLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_ajustado_transformado\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_Y_train_fit_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImportancia_Factores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/inspection/_permutation_importance.py\u001b[0m in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MultimetricScorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mscorers_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0mbaseline_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_weights_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     scores = Parallel(n_jobs=n_jobs)(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/inspection/_permutation_importance.py\u001b[0m in \u001b[0;36m_weights_scorer\u001b[0;34m(scorer, estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in enumerate(Importancia_Factores['importances_mean']):\n",
        "\tprint('Atributo: %0d, Puntuación: %.5f' % (i,j))\n",
        "\n",
        "plt.bar([x for x in range(len(Importancia_Factores['importances_mean']))], Importancia_Factores['importances_mean'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xr6oe1VF8K_A",
        "outputId": "5da583a6-f7f9-491c-f6bd-b9e7f5e83154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Atributo: 0, Puntuación: 0.00000\n",
            "Atributo: 1, Puntuación: 0.00000\n",
            "Atributo: 2, Puntuación: 0.00000\n",
            "Atributo: 3, Puntuación: 0.00000\n",
            "Atributo: 4, Puntuación: 0.00000\n",
            "Atributo: 5, Puntuación: 0.00000\n",
            "Atributo: 6, Puntuación: 0.00000\n",
            "Atributo: 7, Puntuación: 0.00000\n",
            "Atributo: 8, Puntuación: 0.00000\n",
            "Atributo: 9, Puntuación: 0.00000\n",
            "Atributo: 10, Puntuación: 0.00000\n",
            "Atributo: 11, Puntuación: 0.00000\n",
            "Atributo: 12, Puntuación: 0.00000\n",
            "Atributo: 13, Puntuación: 0.00000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-10.**\n",
        "Repite el ejercicio 8 y 9 para el modelo de bosque aleatorio para buscar sus mejores hiperparámetros (realiza la búsqueda con aquellos hiperparámetros que consideres más adecuados) y usando el conjunto de Prueba. Y realiza igualmente el análisis de importancia de factores con este modelo con un diagrama de barras."
      ],
      "metadata": {
        "id": "VUIcDshs8MzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "None"
      ],
      "metadata": {
        "id": "0lKNJNIt8N88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Inkq5YQe8PED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-11.**\n",
        "Repite el ejercicio 8 y 9 para el modelo de regresión lineal múltiple para buscar sus mejores hiperparámetros (realiza la búsqueda con aquellos hiperparámetros que consideres más adecuados) y usando el conjunto de Prueba. Y realiza igualmente el análisis de importancia de factores con este modelo con un diagrama de barras."
      ],
      "metadata": {
        "id": "5LJl6oql8Pc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "None"
      ],
      "metadata": {
        "id": "-YiSnt9t8RfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2iRA78ZC8Rbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ejercicio-12.**\n",
        "Compara tus resultados con los obtenidos por los autores del artículo de Moro-Rita-Vala con respecto a MAPE. Incluye tus conclusiones finales de la actividad.\n"
      ],
      "metadata": {
        "id": "IKW72uyk8Sbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "None"
      ],
      "metadata": {
        "id": "gwpz77W38Uq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8v8HL02W8UmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Fin de la Actividad de la semana 7.**"
      ],
      "metadata": {
        "id": "7ql_r2G-DB_m"
      }
    }
  ]
}
